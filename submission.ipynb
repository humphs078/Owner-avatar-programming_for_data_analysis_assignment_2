{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming for Data Analysis Assignment 2\n",
    "\n",
    "Author - Sean Humphreys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "1. [Problem Statement](#problem-statement)\n",
    "\n",
    "1. [Software Libraries](#software-libraries)\n",
    "\n",
    "1. [Data Cleansing](#data-cleansing)\n",
    "\n",
    "    1. [Carbon Dioxide Data](#co2-data)\n",
    "\n",
    "        1. [Mauna Loa co2 Data](#mauna-loa-co2-data)\n",
    "\n",
    "        2. [IPCC c02 Data](#ipcc-co2-data)\n",
    "\n",
    "        2. [Luthi et al. co2 Data](#luthi-et-al-co2-data)\n",
    "\n",
    "    2. [Temperature Data](#temperature-data)\n",
    "\n",
    "    3. [Methane Data](#methane-data)\n",
    "\n",
    "\n",
    "2. [CO2 v Temperature Anomaly 800yrs to Present](#co2-vs-temperature-anomaly-800k-yr---present)\n",
    "\n",
    "2. [References](#references)\n",
    "\n",
    "3. [Associated Reading](#associated-reading)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement <a id=\"problem-statement\"></a>\n",
    "\n",
    "+ Analyse CO2 vs Temperature Anomaly from 800kyrs – present.\n",
    "\n",
    "+ Examine one other (paleo/modern) features (e.g. CH4 or polar ice-coverage)\n",
    "\n",
    "+ Examine Irish context:\n",
    "    \n",
    "    + [Climate change signals](/literature/the_emergence_of_a_climate_change_signal_in_long_term_irish_meteorological_observations.pdf) : (see Maynooth study: The emergence of a climate change signal in long-term Irish meteorological observations - ScienceDirect)\n",
    "\n",
    "+ Fuse and analyse data from various data sources and format fused data set as a pandas dataframe and export to csv and json formats\n",
    "\n",
    "+ For all of the above variables, analyse the data, the trends and the relationships between them (temporal leads/lags/frequency analysis).\n",
    "\n",
    "+ Predict global temperature anomaly over next few decades (synthesise data) and compare to published climate models if atmospheric CO2 trends continue\n",
    "\n",
    "+ Comment on accelerated warming based on very latest features (e.g. temperature/polar-ice-coverage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Software Libraries <a id=\"software-libraries\"></a>\n",
    "\n",
    "- [Matplotlib](https://matplotlib.org/) (https://matplotlib.org/ - last accessed 13 Dec. 2023) - is an open-source software library for creating static, animated, and interactive visualisations in Python.\n",
    "\n",
    "- [Pandas](https://pandas.pydata.org/) (https://pandas.pydata.org/ - last accessed 3 Nov. 2023) is an open-source software library used in data analytics that allows data analysis and manipulation. Pandas is built on top of the Python programming language. A Pandas DataFrame is a dictionary like container for series objects. A DataFrame is the primary Pandas data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required software libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleansing <a id=\"data-cleansing\"></a>\n",
    "\n",
    "The Pandas software library is used to clean and process datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carbon Dioxide Data <a id=\"carbon-dioxide-data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Mauna Loa co2 Data <a id=\"mauna-loa-c02-data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most recent CO2 dataset in a Comma Separated Value (CSV) file is read in from https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_annmean_mlo.csv.  Using Pandas the CSV) file can be read in as a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://gml.noaa.gov/ccgg/trends/data.html\n",
    "mauna_loa = pd.read_csv('https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_annmean_mlo.csv', skiprows=43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns in the dataset are renamed to logical names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code adapted from # https://sparkbyexamples.com/pandas/rename-columns-with-list-in-pandas-dataframe/\n",
    "cols = ['year', 'co2_ppmv', 'unc']\n",
    "\n",
    "mauna_loa.columns = cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An unnecessary column is removed from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code adapted from https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html [Accessed 13 Dec. 2023]\n",
    "mauna_loa.drop(['unc'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An additional column is added to the dataset that calculates the year no before the 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mauna_loa['years_before_present'] = 2023 - mauna_loa['year']\n",
    "\n",
    "# sort the data based on the year before present. Based on code from - https://saturncloud.io/blog/how-to-sort-pandas-dataframe-from-one-column/ [Accessed 13 Dec. 2023].\n",
    "mauna_loa = mauna_loa.sort_values('years_before_present')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns in the dataset are reordered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from code found here - https://practicaldatascience.co.uk/data-science/how-to-reorder-pandas-dataframe-columns [Accessed 13 Dec. 2023]\n",
    "mauna_loa = mauna_loa.reindex(columns=['yr_bp', 'co2_ppmv', 'year', 'years_before_present'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  IPCC co2 Data <a id=\"ipcc-c02-data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The excel spreadsheet with historic IPCC co2 data is read in as a Pandas Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_data = pd.read_excel('datasets/historic/co2/grl52461-sup-0003-supplementary.xls', sheet_name='all records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrames to capture specific subsets of data from assorted studies in the master dataset are defined. These subsets will be stitched together to create a composite dataset of historic co2 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use iloc to create subsets of data from the master dataset\n",
    "rubino = master_data.iloc[90:, [83, 86]]\n",
    "macfarling = master_data.iloc[137:, 68:70]\n",
    "monnin = master_data.iloc[25:120, 2:4]\n",
    "marcott = master_data.iloc[31:321, 98:100]\n",
    "ahn = master_data.iloc[7:202, 89:91]\n",
    "bereiter = master_data.iloc[28:106, 34:36]\n",
    "bereiter_2 = master_data.iloc[60:154, 39:41]\n",
    "schneider = master_data.iloc[6:, 65:67]\n",
    "petit = master_data.iloc[124:348, 7:9]\n",
    "siegenthaler = master_data.iloc[6:26, 20:22]\n",
    "siegenthaler_2 = master_data.iloc[6:226, 15:17]\n",
    "bereiter_3 = master_data.iloc[37:, 102:104]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns in each dataframe are renamed to logical names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rubino.rename(columns=({'Unnamed: 83':'yr_bp', 'Unnamed: 86':'co2_ppmv'}), inplace=True)\n",
    "macfarling.rename(columns=({'Law Dome (0-2 kyr BP)':'yr_bp', 'Unnamed: 69':'co2_ppmv'}), inplace=True)\n",
    "monnin.rename(columns=({'Unnamed: 2':'yr_bp', 'Unnamed: 3':'co2_ppmv'}), inplace=True)\n",
    "marcott.rename(columns=({'Unnamed: 98':'yr_bp', 'Unnamed: 99':'co2_ppmv'}), inplace=True)\n",
    "ahn.rename(columns=({'Unnamed: 89':'yr_bp', 'Unnamed: 90':'co2_ppmv'}), inplace=True)\n",
    "bereiter.rename(columns=({'Unnamed: 34':'yr_bp', 'Unnamed: 35':'co2_ppmv'}), inplace=True)\n",
    "bereiter_2.rename(columns=({'Unnamed: 39':'yr_bp', 'Unnamed: 40':'co2_ppmv'}), inplace=True)\n",
    "schneider.rename(columns=({'Unnamed: 65':'yr_bp', 'Unnamed: 66':'co2_ppmv'}), inplace=True)\n",
    "petit.rename(columns=({'Unnamed: 7':'yr_bp', 'Unnamed: 8':'co2_ppmv'}), inplace=True)\n",
    "siegenthaler.rename(columns=({'Unnamed: 20':'yr_bp', 'Unnamed: 21':'co2_ppmv'}), inplace=True)\n",
    "siegenthaler_2.rename(columns=({'Unnamed: 15':'yr_bp', 'Unnamed: 16':'co2_ppmv'}), inplace=True)\n",
    "bereiter_3.rename(columns=({'Unnamed: 102':'yr_bp', 'Unnamed: 103':'co2_ppmv'}), inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function is defined to carry out a number of processing actions on each DataFrame. The `year()` function:\n",
    "\n",
    "+ creates a columns that calculates the year based on the before present value\n",
    "\n",
    "+ creates a column that calculates the year before present values\n",
    "\n",
    "+ drops any rows with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def year(sample):\n",
    "    sample['year'] = 1950-(sample['yr_bp'])\n",
    "    sample['years_before_present'] = 2023 - sample['year']\n",
    "    sample.dropna(axis=0, inplace=True)\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a for loop, each of the subsets of data can be passed to the `year()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "studies = [rubino, macfarling, monnin, marcott, ahn, bereiter, bereiter_2, schneider, petit, siegenthaler, siegenthaler_2, bereiter_3]\n",
    "\n",
    "for study in studies:\n",
    "    year(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the subsets of co2 data is concatenated into one DataFrame to create a composite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code adapted from https://pandas.pydata.org/docs/reference/api/pandas.concat.html [Accessed 13 Dec. 2023].\n",
    "frames = [mauna_loa, rubino, macfarling, monnin, marcott, ahn, bereiter, bereiter_2, schneider, petit, siegenthaler, siegenthaler_2, bereiter_3]\n",
    "\n",
    "ipcc_full_co2_data = pd.concat(frames, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Luthi et al. co2 Data <a id=\"Luthi-c02-data\"></a>\n",
    "\n",
    "The historic co2 data to 800k years before present is read in as a Pandas DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "co2_ipcc = pd.read_excel('/home/humphs01/Documents/ATU/programming_for_data_analysis_assignment_2/datasets/historic/co2/41586_2008_BFnature06949_MOESM31_ESM.xls', sheet_name='2.  Vostok-TD-Dome C')\n",
    "co2_ipcc_new = pd.read_excel('/home/humphs01/Documents/ATU/programming_for_data_analysis_assignment_2/datasets/historic/co2/41586_2008_BFnature06949_MOESM31_ESM.xls', sheet_name='1.  new CO2 data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrames to capture specific subsets of data from assorted studies in the master dataset are defined. These subsets will be stitched together to create a composite dataset of historic co2 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "monnin_ipcc = co2_ipcc.iloc[6:189, 1:3]\n",
    "pettit_ipcc = co2_ipcc.iloc[19:353, 5:7]\n",
    "siegenthaler_1_ipcc = co2_ipcc.iloc[6:26, 16:18]\n",
    "siegenthaler_2_ipcc = co2_ipcc.iloc[6:328, 12:14]\n",
    "luthi_ipcc = co2_ipcc_new.iloc[16:253, 1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns in each dataframe are renamed to logical names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "monnin_ipcc.rename(columns=({'Unnamed: 1':'yr_bp', 'Unnamed: 2':'co2_ppmv'}), inplace=True)\n",
    "pettit_ipcc.rename(columns=({'Unnamed: 5':'yr_bp', 'Unnamed: 6':'co2_ppmv'}), inplace=True)\n",
    "siegenthaler_1_ipcc.rename(columns=({'Unnamed: 16':'yr_bp', 'Unnamed: 17':'co2_ppmv'}), inplace=True)\n",
    "siegenthaler_2_ipcc.rename(columns=({'Unnamed: 12':'yr_bp', 'Unnamed: 13':'co2_ppmv'}), inplace=True)\n",
    "luthi_ipcc.rename(columns=({'Unnamed: 1':'yr_bp', 'Unnamed: 2':'co2_ppmv'}), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a for loop, each of the subsets of data can be passed to the `year()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "studies = [monnin_ipcc ,pettit_ipcc, siegenthaler_1_ipcc, siegenthaler_2_ipcc, luthi_ipcc]\n",
    "\n",
    "for study in studies:\n",
    "    year(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the subsets of co2 data is concatenated into one DataFrame to create a composite of the data in Luthi et al (2008)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "luthi_frames = [mauna_loa, rubino, macfarling, monnin, marcott, ahn, bereiter, bereiter_2, schneider, petit, siegenthaler, siegenthaler_2, bereiter_3]\n",
    "\n",
    "luthi_full_co2_data = pd.concat(luthi_frames, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the subsets of co2 data is concatenated into one DataFrame to create a composite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature Data <a id=\"temperature-data\"></a>\n",
    "\n",
    "The temperature from from 1880 to 2022 in this dataset is sourced from [NASA](https://data.giss.nasa.gov/gistemp/graphs/graph_data/Global_Mean_Estimates_based_on_Land_and_Ocean_Data/graph.txt) (https://data.giss.nasa.gov/gistemp/graphs/graph_data/Global_Mean_Estimates_based_on_Land_and_Ocean_Data/graph.txt [Accessed 12 Dec. 2023].). [2]\n",
    "\n",
    "Temperature data from 1880 to 800k years from the 2023 was sourced from [https://www.temperaturerecord.org/#sources](https://www.temperaturerecord.org/#sources) accessed 13 Dec. 2023. [3] & [4]\n",
    "\n",
    "All of the temperature data is compared to the long-term average from 1951 to 1980.\n",
    "\n",
    "[2] Credits - Snyder, C.W. 2016.\n",
    "\n",
    "[3] Credits - Marcott et al, 2013\n",
    "\n",
    "[4] Credits - Shakun et al, 2012\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Pandas modern temperature data is read in from the NASA website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasa_temp = pd.read_csv('https://data.giss.nasa.gov/gistemp/graphs/graph_data/Global_Mean_Estimates_based_on_Land_and_Ocean_Data/graph.txt', \n",
    "                       skiprows=5, header=None, sep = ' ', skipinitialspace=True, engine='python', names=['year', 'temp_anomaly', 'lowness'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An unnecessary column is dropped from the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasa_temp.drop(['lowness'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A column with the year before present is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasa_temp['yr_bp'] = 1950 - nasa_temp['year']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remaining columns are renamed to a standard naming convention that will be used with temperature data from another source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasa_temp = nasa_temp.reindex(columns=['year', 'yr_bp', 'temp_anomaly'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NASA data is sorted by year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasa_temp = nasa_temp.sort_values('year', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre 1800's temperature data is read in from worksheets in an excel spreadsheet that contains all of the historic temperature data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "moberg_temp = pd.read_excel('datasets/historic/temperature/temperature_dataset.xlsx', \n",
    "                            sheet_name='2,000 yr',  names=['year', 'yr_bp', 'temp_anomaly', 'x', 'y', 'z'])\n",
    "clark_temp = pd.read_excel('datasets/historic/temperature/temperature_dataset.xlsx', \n",
    "                           sheet_name='20,000 yr', names=['yr_bp', 'temp_anomaly', 'x', 'y', 'z'])\n",
    "shakun_temp = pd.read_excel('datasets/historic/temperature/temperature_dataset.xlsx', \n",
    "                            sheet_name='800,000 yr', names=['yr_bp', 'temp_anomaly', 'x', 'y', 'z'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unneeded columns are removed from the DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "moberg_temp.drop(['x', 'y', 'z'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remaining columns are re-ordered to make them consistent with the rest of the temperature DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "moberg_temp.drop(moberg_temp.index[0:100], axis = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A number of precessing tasks are grouped together in a function. The `temp_year()` function removes unneeded columns from the DataFrame and adds a column to calculate the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp_year(sample):\n",
    "    sample.drop(['x', 'y', 'z'],axis=1, inplace=True)\n",
    "    sample['year'] = 1950 - sample['yr_bp']\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a for loop the relevant datasets are paased to the `temp_year()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [clark_temp, shakun_temp]\n",
    "\n",
    "for sample in samples:\n",
    "    temp_year(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns in the DataFrames are re-ordered to be consistent with the other temperature DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "clark_temp = clark_temp.reindex(columns=['year', 'yr_bp', 'temp_anomaly'])\n",
    "shakun_temp = shakun_temp.reindex(columns=['year', 'yr_bp', 'temp_anomaly'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rows are dropped from each of the  DataFrames so that there is no overlap between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "clark_temp.drop(clark_temp.index[0:19], axis = 0, inplace = True)\n",
    "shakun_temp.drop(shakun_temp.index[0:7], axis = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the temperature DataFrames are concatenated to give a composite record of the temperature anomaly over the last 800k years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_temp = [nasa_temp, moberg_temp, clark_temp, shakun_temp]\n",
    "\n",
    "full_temp_data = pd.concat(frames_temp, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>yr_bp</th>\n",
       "      <th>temp_anomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022</td>\n",
       "      <td>-72</td>\n",
       "      <td>0.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021</td>\n",
       "      <td>-71</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>-70</td>\n",
       "      <td>1.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>-69</td>\n",
       "      <td>0.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018</td>\n",
       "      <td>-68</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2478</th>\n",
       "      <td>-784050</td>\n",
       "      <td>786000</td>\n",
       "      <td>-0.563657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2479</th>\n",
       "      <td>-787050</td>\n",
       "      <td>789000</td>\n",
       "      <td>-0.991467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>-790050</td>\n",
       "      <td>792000</td>\n",
       "      <td>-1.155061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2481</th>\n",
       "      <td>-793050</td>\n",
       "      <td>795000</td>\n",
       "      <td>-2.457660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2482</th>\n",
       "      <td>-796050</td>\n",
       "      <td>798000</td>\n",
       "      <td>-1.684176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2483 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        year   yr_bp  temp_anomaly\n",
       "0       2022     -72      0.890000\n",
       "1       2021     -71      0.850000\n",
       "2       2020     -70      1.020000\n",
       "3       2019     -69      0.980000\n",
       "4       2018     -68      0.850000\n",
       "...      ...     ...           ...\n",
       "2478 -784050  786000     -0.563657\n",
       "2479 -787050  789000     -0.991467\n",
       "2480 -790050  792000     -1.155061\n",
       "2481 -793050  795000     -2.457660\n",
       "2482 -796050  798000     -1.684176\n",
       "\n",
       "[2483 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_temp_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methane Data <a id=\"methane-data\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CO2 vs Temperature Anomaly 800k Yr - Present <a id=\"CO2-vs-Temperature-Anomaly-800k-Yr---Present\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis <a id=\"data-cleansing\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine one other (paleo/modern) feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Irish context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fused Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References <a id=\"references\"></a>\n",
    "\n",
    "Bereiter et al. (2014), Revision of the EPICA Dome C CO2 record from 800 to 600 kyr before present, Geophysical Research Letters, doi: 10.1002/2014GL061957.\n",
    "\n",
    "Lüthi, D., Le Floch, M., Bereiter, B., Blunier, T., Barnola, J.-M., Siegenthaler, U., Raynaud, D., Jouzel, J., Fischer, H., Kawamura, K. and Stocker, T.F. (2008). High-resolution carbon dioxide concentration record 650,000–800,000 years before present. Nature, 453(7193), pp.379–382. doi:https://doi.org/10.1038/nature06949.\n",
    "\n",
    "Marcott, S.A., Shakun, J.D., Clark, P.U. and Mix, A.C. (2013). A Reconstruction of Regional and Global Temperature for the Past 11,300 Years. Science, 339(6124), pp.1198–1201. doi:https://doi.org/10.1126/science.1228026.\n",
    "\n",
    "\n",
    "Naveen (2022). How to Rename Columns With List in Pandas. [online] Spark By {Examples}. Available at: https://sparkbyexamples.com/pandas/rename-columns-with-list-in-pandas-dataframe/ [Accessed 13 Dec. 2023].\n",
    "\n",
    "pandas.pydata.org. (n.d.). pandas.concat — pandas 1.3.4 documentation. [online] Available at: https://pandas.pydata.org/docs/reference/api/pandas.concat.html. [Accessed 13 Dec. 2023].\n",
    "\n",
    "pandas.pydata.org. (n.d.). pandas.DataFrame.drop — pandas 1.2.4 documentation. [online] Available at: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html. [Accessed 13 Dec. 2023].\n",
    "\n",
    "practicaldatascience.co.uk. (2022). How to reorder Pandas dataframe columns. [online] Available at: https://practicaldatascience.co.uk/data-science/how-to-reorder-pandas-dataframe-columns. [Accessed 13 Dec. 2023].\n",
    "\n",
    "saturncloud.io. (2023). How to Sort Pandas DataFrame by One or Multiple Column | Saturn Cloud Blog. [online] Available at: https://saturncloud.io/blog/\n",
    "how-to-sort-pandas-dataframe-from-one-column/ [Accessed 13 Dec. 2023].\n",
    "\n",
    "Shakun, J.D., Clark, P.U., He, F., Marcott, S.A., Mix, A.C., Liu, Z., Otto-Bliesner, B., Schmittner, A. and Bard, E. (2012). Global warming preceded by increasing carbon dioxide concentrations during the last deglaciation. Nature, [online] 484(7392), pp.49–54. doi:https://doi.org/10.1038/nature10915.\n",
    "\n",
    "Snyder, C.W. (2016). Evolution of global temperature over the past two million years. Nature, [online] 538(7624), pp.226–228. doi:https://doi.org/10.1038/nature19798."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Associated Reading <a id=\"associated-reading\"></a>\n",
    "\n",
    "Matplotlib (2012). Matplotlib: Python plotting — Matplotlib 3.1.1 documentation. [online] Matplotlib.org. Available at: https://matplotlib.org/. [Accessed 13 Dec. 2023].\n",
    "\n",
    "Pandas (2018). Python Data Analysis Library — pandas: Python Data Analysis Library. [online] Pydata.org. Available at: https://pandas.pydata.org/. [Accessed 13 Dec. 2023]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook Ends"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
