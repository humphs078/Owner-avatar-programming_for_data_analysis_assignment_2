{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming for Data Analysis Assignment 2\n",
    "\n",
    "Author - Sean Humphreys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "1. [Problem Statement](#problem-statement)\n",
    "\n",
    "1. [Software Libraries](#software-libraries)\n",
    "\n",
    "2. [Data Exploration and Cleansing](#data-exploration-and-cleansing)\n",
    "\n",
    "    1. [Carbon Dioxide Data](#co2-data)\n",
    "\n",
    "        1. [Luthi et al. co2 Data](#luthi-et-al-co2-data)\n",
    "\n",
    "        2. [IPCC CO2 Data](#ipcc-CO2-data)\n",
    "\n",
    "        3. [Mauna Loa CO2 Data](#mauna-loa-co2-data)\n",
    "\n",
    "    2. [Temperature Data](#temperature-data)\n",
    "\n",
    "        1. [Jouzel (2007) Temperature Data](#jouzel-2007-temperature-data)\n",
    "\n",
    "        2. [NOAA Temperature Data](#noaa-temperature-data)\n",
    "\n",
    "        3. [Further Temperature Data](#further-temperature-data)\n",
    "\n",
    "        4. [Monthly Temperature Data](#monthly-temperature-data)\n",
    "\n",
    "    3. [Methane Data](#methane-data)\n",
    "\n",
    "    4. [Irish Data](#irish-data)\n",
    "\n",
    "        1. [Irish Temerature Data](#irish-temperature-data)\n",
    "\n",
    "        2. [Irish Precipitation Data](#irish-precipitation-data)\n",
    "\n",
    "    4. [Fused Dataset](#fused-dataset)\n",
    "\n",
    "\n",
    "2. [Analysis](#analysis)\n",
    "\n",
    "    1. [Carbon Dioxide](#carbon-dioxide)\n",
    "\n",
    "    2. [Temperature](#temperature)\n",
    "\n",
    "    3. [Methane](#methane)\n",
    "\n",
    "3. [Irish Context](#irish-context)\n",
    "\n",
    "    1. [Irish Context - Temperature](#irish-context---temperature)\n",
    "    \n",
    "    2. [Irish Context - Precipitation](#irish-context---precipitation)\n",
    "\n",
    "4. [Predictive Model](#predictive-model)\n",
    "\n",
    "2. [References](#references)\n",
    "\n",
    "3. [Associated Reading](#associated-reading)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement <a id=\"problem-statement\"></a>\n",
    "\n",
    "+ Analyse CO2 vs Temperature Anomaly from 800kyrs – present.\n",
    "\n",
    "+ Examine one other (paleo/modern) features (e.g. CH4 or polar ice-coverage)\n",
    "\n",
    "+ Examine Irish context:\n",
    "    \n",
    "    + [Climate change signals](/literature/the_emergence_of_a_climate_change_signal_in_long_term_irish_meteorological_observations.pdf) : (see Maynooth study: The emergence of a climate change signal in long-term Irish meteorological observations - ScienceDirect)\n",
    "\n",
    "+ Fuse and analyse data from various data sources and format fused data set as a pandas dataframe and export to csv and json formats\n",
    "\n",
    "+ For all of the above variables, analyse the data, the trends and the relationships between them (temporal leads/lags/frequency analysis).\n",
    "\n",
    "+ Predict global temperature anomaly over next few decades (synthesise data) and compare to published climate models if atmospheric CO2 trends continue\n",
    "\n",
    "+ Comment on accelerated warming based on very latest features (e.g. temperature/polar-ice-coverage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Software Libraries <a id=\"software-libraries\"></a>\n",
    "\n",
    "- [Datetime](https://docs.python.org/3/library/datetime.html) (https://docs.python.org/3/library/datetime.html - last accessed 21 Dec. 2023) - supplies classes for manipulating dates and times.\n",
    "\n",
    "- [Matplotlib](https://matplotlib.org/) (https://matplotlib.org/ - last accessed 13 Dec. 2023) - is an open-source software library for creating static, animated, and interactive visualisations in Python.\n",
    "\n",
    "- [Numpy](https://numpy.org/doc/stable/index.html) (https://numpy.org/doc/stable/index.html - last accessed 8. Nov 2023) - is an open-source software library for the Python, adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays.\n",
    "\n",
    "- [Pandas](https://pandas.pydata.org/) (https://pandas.pydata.org/ - last accessed 3 Nov. 2023) is an open-source software library used in data analytics that allows data analysis and manipulation. Pandas is built on top of the Python programming language. A Pandas DataFrame is a dictionary like container for series objects. A DataFrame is the primary Pandas data structure.\n",
    "\n",
    "- [scikit-learn](https://scikit-learn.org/stable/index.html) (https://scikit-learn.org/stable/index.html) - are a set of tools used for predictive analysis. It is used extensively in machine learning.\n",
    "\n",
    "- [SciPy](https://scipy.org/) (https://scipy.org/ - last accessed 21 Nov. 2023) provides algorithms for scientific computing in Python. SciPy is a portmanteau of Scientific Python. It is a scientific computation library that uses Numpy underneath.\n",
    "\n",
    "- [Seaborn](https://seaborn.pydata.org/) (https://seaborn.pydata.org/ - last accessed 23 Nov. 2023) - is visualisation software that is built on matplotlib. It offers a high-level interface for drawing attractive and informative statistical graphics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required software libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy import signal\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration and Cleansing <a id=\"data-exploration-and-cleansing\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pandas software library is used to clean and process datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carbon Dioxide Data <a id=\"carbon-dioxide-data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Luthi et al. Carbon Dixoide Data <a id=\"luthi-et-al.-carbon-dioxide-data\"></a>\n",
    "\n",
    "The first carbon dataset (CO2) is sourced from Luthi et al (2008.) This dataset is a composite of a number of samples of CO2 data from studies on antarctic ice core analysis. Luthi et al. use the EDC3 chronology to describe the age of the samples in the dataset. This EDC3 chronology discussed further [here](#data-analysis). \n",
    "\n",
    "Historic CO2 data in this dataset ranges from the year 1813 to 800k years before present.\n",
    "\n",
    "To process the data it is read in as a Pandas DataFrame from separate worksheets in an Microsoft Excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code adapted from https://www.mybib.com/tools/harvard-referencing-generator [Accessed 19 Dec. 2023]\n",
    "co2_ipcc = pd.read_excel(\n",
    "    'datasets/historic/co2/41586_2008_BFnature06949_MOESM31_ESM.xls', sheet_name='2.  Vostok-TD-Dome C')\n",
    "co2_ipcc_new = pd.read_excel(\n",
    "    'datasets/historic/co2/41586_2008_BFnature06949_MOESM31_ESM.xls', sheet_name='1.  new CO2 data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrames to capture specific subsets of data from assorted studies in the master dataset are defined. These subsets will be stitched together to create a composite dataset of historic co2 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from code found here - https://www.shanelynn.ie/pandas-iloc-loc-select-rows-and-columns-dataframe/ [Accessed 19 Dec. 2023].\n",
    "monnin_luthi = co2_ipcc.iloc[6:189, 1:3]\n",
    "pettit_luthi = co2_ipcc.iloc[19:353, 5:7]\n",
    "siegenthaler_1_luthi = co2_ipcc.iloc[6:26, 16:18]\n",
    "siegenthaler_2_luthi = co2_ipcc.iloc[6:328, 12:14]\n",
    "luthi_luthi = co2_ipcc_new.iloc[16:253, 1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns in each dataframe are renamed to logical names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "monnin_luthi.rename(columns=({'Unnamed: 1':'yr_bp', 'Unnamed: 2':'co2_ppmv'}), inplace=True)\n",
    "pettit_luthi.rename(columns=({'Unnamed: 5':'yr_bp', 'Unnamed: 6':'co2_ppmv'}), inplace=True)\n",
    "siegenthaler_1_luthi.rename(columns=({'Unnamed: 16':'yr_bp', 'Unnamed: 17':'co2_ppmv'}), inplace=True)\n",
    "siegenthaler_2_luthi.rename(columns=({'Unnamed: 12':'yr_bp', 'Unnamed: 13':'co2_ppmv'}), inplace=True)\n",
    "luthi_luthi.rename(columns=({'Unnamed: 1':'yr_bp', 'Unnamed: 2':'co2_ppmv'}), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function is defined to carry out a number of processing actions on each DataFrame. The `year()` function:\n",
    "\n",
    "+ creates a columns that calculates the NUMBER OF yearS before 2023\n",
    "\n",
    "+ creates a column that calculates the year\n",
    "\n",
    "+ drops any rows with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def year(sample):\n",
    "    sample['years_before_2023'] = 2023 - (1950-(sample['yr_bp']))\n",
    "    sample['year'] = 1950 - (sample['yr_bp'])\n",
    "    sample.drop('yr_bp', axis=1, inplace=True)\n",
    "    sample.dropna(axis=0, inplace=True)\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a for loop, each of the subsets of data can be passed to the `year()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "studies = [monnin_luthi ,pettit_luthi, siegenthaler_1_luthi, siegenthaler_2_luthi, luthi_luthi]\n",
    "\n",
    "for study in studies: year(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the subsets of CO2 data is concatenated into one DataFrame to create a composite of the data in Luthi et al (2008) so that the trending carbon dioxide levels for the 800,000 year period can be plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code adapted from https://pandas.pydata.org/docs/reference/api/pandas.concat.html [Accessed 13 Dec. 2023]. \n",
    "luthi_frames = [monnin_luthi ,pettit_luthi, siegenthaler_1_luthi, siegenthaler_2_luthi, luthi_luthi]\n",
    "\n",
    "luthi_full_co2_data = pd.concat(luthi_frames, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The concatenated dataset is explored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>co2_ppmv</th>\n",
       "      <th>years_before_2023</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>280.4</td>\n",
       "      <td>210</td>\n",
       "      <td>1813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>274.9</td>\n",
       "      <td>341</td>\n",
       "      <td>1682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>277.9</td>\n",
       "      <td>352</td>\n",
       "      <td>1671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>279.1</td>\n",
       "      <td>468</td>\n",
       "      <td>1555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>281.9</td>\n",
       "      <td>477</td>\n",
       "      <td>1546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  co2_ppmv years_before_2023  year\n",
       "0    280.4               210  1813\n",
       "1    274.9               341  1682\n",
       "2    277.9               352  1671\n",
       "3    279.1               468  1555\n",
       "4    281.9               477  1546"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luthi_full_co2_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1096 entries, 0 to 1095\n",
      "Data columns (total 3 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   co2_ppmv           1096 non-null   object\n",
      " 1   years_before_2023  1096 non-null   object\n",
      " 2   year               1096 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 25.8+ KB\n"
     ]
    }
   ],
   "source": [
    "luthi_full_co2_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables are cast to Pandas Dtypes that can be used for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code adapted from https://www.geeksforgeeks.org/python-pandas-dataframe-astype/ [Accessed 15 Dec. 2023].\n",
    "luthi_full_co2_data = luthi_full_co2_data.astype({'co2_ppmv':'float64', 'years_before_2023': 'int', 'year':'int'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1096 entries, 0 to 1095\n",
      "Data columns (total 3 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   co2_ppmv           1096 non-null   float64\n",
      " 1   years_before_2023  1096 non-null   int32  \n",
      " 2   year               1096 non-null   int32  \n",
      "dtypes: float64(1), int32(2)\n",
      "memory usage: 17.3 KB\n"
     ]
    }
   ],
   "source": [
    "luthi_full_co2_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DataFrame is insepcted for Duplicate vales in the *years_before_2023* column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>co2_ppmv</th>\n",
       "      <th>years_before_2023</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>275.2</td>\n",
       "      <td>409456</td>\n",
       "      <td>-407433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>274.2</td>\n",
       "      <td>409456</td>\n",
       "      <td>-407433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     co2_ppmv  years_before_2023    year\n",
       "530     275.2             409456 -407433\n",
       "531     274.2             409456 -407433"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code adapted from https://stackoverflow.com/questions/14657241/how-do-i-get-a-list-of-all-the-duplicate-items-using-pandas-in-python Accessed 22 Dec. 2023\n",
    "pd.concat(g for _, g in luthi_full_co2_data.groupby(\"years_before_2023\") if len(g) > 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen there is two entries for the year -407433. The simplest way to manage this is to drop the year with the smaller value. As the difference is 1 ppmv the effect is negligible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "luthi_full_co2_data.drop(531, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns are reordered to a more logical arrangement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from code found here:\n",
    "# https://practicaldatascience.co.uk/data-science/how-to-reorder-pandas-dataframe-columns [Accessed 13 Dec. 2023]\n",
    "luthi_full_co2_data = luthi_full_co2_data.reindex(columns=['years_before_2023', 'year', 'co2_ppmv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>years_before_2023</th>\n",
       "      <th>year</th>\n",
       "      <th>co2_ppmv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>210</td>\n",
       "      <td>1813</td>\n",
       "      <td>280.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>341</td>\n",
       "      <td>1682</td>\n",
       "      <td>274.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>352</td>\n",
       "      <td>1671</td>\n",
       "      <td>277.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>468</td>\n",
       "      <td>1555</td>\n",
       "      <td>279.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>477</td>\n",
       "      <td>1546</td>\n",
       "      <td>281.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   years_before_2023  year  co2_ppmv\n",
       "0                210  1813     280.4\n",
       "1                341  1682     274.9\n",
       "2                352  1671     277.9\n",
       "3                468  1555     279.1\n",
       "4                477  1546     281.9"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luthi_full_co2_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  IPCC CO2 Data <a id=\"ipcc-co2-data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A second CO2 dataset is sourced from the [The Intergovernmental Panel on Climate Change (IPCC)](https://www.ipcc.ch/) (https://www.ipcc.ch/). This dataset is a composite of a number of samples of carbon dioxide data from studies on ice core analysis. The samples have been dated using the The Antarctic Ice Core Chronology (AICC2012) system. This is discussed further [here](#data-analysis).\n",
    "\n",
    "This dataset contains measurements of CO2. The range of years in the composite dataset is from 1950 to 803,182 years from 2023.\n",
    "\n",
    "The excel spreadsheet with historic IPCC co2 data is read in as a Pandas Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipcc_c02_data = pd.read_excel(\n",
    "                              'datasets/historic/co2/grl52461-sup-0003-supplementary.xls', \n",
    "                              sheet_name='all records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrames to capture specific subsets of data from assorted studies in the master dataset are defined. These subsets will be stitched together to create a composite dataset of historic co2 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use iloc to create subsets of data from the master dataset\n",
    "rubino = ipcc_c02_data.iloc[90:, [83, 86]]\n",
    "macfarling = ipcc_c02_data.iloc[137:, 68:70]\n",
    "monnin = ipcc_c02_data.iloc[25:120, 2:4]\n",
    "marcott = ipcc_c02_data.iloc[31:321, 98:100]\n",
    "ahn = ipcc_c02_data.iloc[7:202, 89:91]\n",
    "bereiter = ipcc_c02_data.iloc[28:106, 34:36]\n",
    "bereiter_2 = ipcc_c02_data.iloc[60:154, 39:41]\n",
    "schneider = ipcc_c02_data.iloc[6:, 65:67]\n",
    "petit = ipcc_c02_data.iloc[124:348, 7:9]\n",
    "siegenthaler = ipcc_c02_data.iloc[6:26, 20:22]\n",
    "siegenthaler_2 = ipcc_c02_data.iloc[6:226, 15:17]\n",
    "bereiter_3 = ipcc_c02_data.iloc[37:, 102:104]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns in each dataframe are renamed to logical names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rubino.rename(columns=({'Unnamed: 83':'yr_bp', 'Unnamed: 86':'co2_ppmv'}), inplace=True)\n",
    "macfarling.rename(columns=({'Law Dome (0-2 kyr BP)':'yr_bp', 'Unnamed: 69':'co2_ppmv'}), inplace=True)\n",
    "monnin.rename(columns=({'Unnamed: 2':'yr_bp', 'Unnamed: 3':'co2_ppmv'}), inplace=True)\n",
    "marcott.rename(columns=({'Unnamed: 98':'yr_bp', 'Unnamed: 99':'co2_ppmv'}), inplace=True)\n",
    "ahn.rename(columns=({'Unnamed: 89':'yr_bp', 'Unnamed: 90':'co2_ppmv'}), inplace=True)\n",
    "bereiter.rename(columns=({'Unnamed: 34':'yr_bp', 'Unnamed: 35':'co2_ppmv'}), inplace=True)\n",
    "bereiter_2.rename(columns=({'Unnamed: 39':'yr_bp', 'Unnamed: 40':'co2_ppmv'}), inplace=True)\n",
    "schneider.rename(columns=({'Unnamed: 65':'yr_bp', 'Unnamed: 66':'co2_ppmv'}), inplace=True)\n",
    "petit.rename(columns=({'Unnamed: 7':'yr_bp', 'Unnamed: 8':'co2_ppmv'}), inplace=True)\n",
    "siegenthaler.rename(columns=({'Unnamed: 20':'yr_bp', 'Unnamed: 21':'co2_ppmv'}), inplace=True)\n",
    "siegenthaler_2.rename(columns=({'Unnamed: 15':'yr_bp', 'Unnamed: 16':'co2_ppmv'}), inplace=True)\n",
    "bereiter_3.rename(columns=({'Unnamed: 102':'yr_bp', 'Unnamed: 103':'co2_ppmv'}), inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a *for loop*, a number of actions are performed on each of the subsets of data. In the source data the year is a floating point integer. That will cause an inaccuracy of 1 year when calculating the number of years before 2023. To account for this the floating point integer in the *yr_bp* column is rounded down to the nearest whole number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "studies = [rubino, macfarling, monnin, marcott, ahn, bereiter, bereiter_2, \n",
    "           schneider, petit, siegenthaler, siegenthaler_2, bereiter_3]\n",
    "\n",
    "# the last line in the function is adapted from code found here:\n",
    "# https://stackoverflow.com/questions/35873927/rounding-down-values-in-pandas-dataframe-column-with-nans\n",
    "# accessed 23 Dec. 2023\n",
    "for study in studies:\n",
    "    study.dropna(axis=0, inplace=True)\n",
    "    study['yr_bp'].astype(int)\n",
    "    study['yr_bp'] = study['yr_bp'].apply(np.floor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the elements in the *studies* list is passed to the `year()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for study in studies: year(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the subsets of CO2 data is concatenated into one DataFrame to create a composite of the subsets of data. FRom this DataFrame the trending levels of carbon dioxide over time are plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code adapted from https://pandas.pydata.org/docs/reference/api/pandas.concat.html [Accessed 13 Dec. 2023].\n",
    "frames = [rubino, macfarling, monnin, marcott, ahn, bereiter, bereiter_2, schneider, petit, siegenthaler, siegenthaler_2, bereiter_3]\n",
    "\n",
    "ipcc_full_co2_data = pd.concat(frames, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `info ()` gives an indication of the datatypes in the concatenated DataFrame. All variables are *objects*. This limits they type of analysis that can be carried out on these variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1852 entries, 0 to 1851\n",
      "Data columns (total 3 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   co2_ppmv           1852 non-null   object\n",
      " 1   years_before_2023  1852 non-null   object\n",
      " 2   year               1852 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 43.5+ KB\n"
     ]
    }
   ],
   "source": [
    "ipcc_full_co2_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pandas `astype()` is used to cast a Pandas object to a specific type of datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipcc_full_co2_data = ipcc_full_co2_data.astype({'co2_ppmv':'float64', 'years_before_2023':'int', 'year':'int'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1852 entries, 0 to 1851\n",
      "Data columns (total 3 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   co2_ppmv           1852 non-null   float64\n",
      " 1   years_before_2023  1852 non-null   int32  \n",
      " 2   year               1852 non-null   int32  \n",
      "dtypes: float64(1), int32(2)\n",
      "memory usage: 29.1 KB\n"
     ]
    }
   ],
   "source": [
    "ipcc_full_co2_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon checking the first five rows of the DataFrame it is apparent that some years have more than one entry. These are not duplicate rows as such but rather years where there more than one measurement of CO2 was taken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>co2_ppmv</th>\n",
       "      <th>years_before_2023</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>316.334020</td>\n",
       "      <td>64</td>\n",
       "      <td>1959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>316.101403</td>\n",
       "      <td>64</td>\n",
       "      <td>1959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>314.572166</td>\n",
       "      <td>65</td>\n",
       "      <td>1958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>315.270355</td>\n",
       "      <td>65</td>\n",
       "      <td>1958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>316.325380</td>\n",
       "      <td>65</td>\n",
       "      <td>1958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     co2_ppmv  years_before_2023  year\n",
       "0  316.334020                 64  1959\n",
       "1  316.101403                 64  1959\n",
       "2  314.572166                 65  1958\n",
       "3  315.270355                 65  1958\n",
       "4  316.325380                 65  1958"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipcc_full_co2_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for duplicate values in the *years_before_2023* column reveals that there is 62 rows that have the same value for the *year_before_2023* column. The approach to deal with these years is to drop the duplicates but keep the first row. This is blunt but due to the minimal difference between the CO2 value for each duplicate, the effect on any analysis carried out on the dataset will be negligible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>co2_ppmv</th>\n",
       "      <th>years_before_2023</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>316.334020</td>\n",
       "      <td>64</td>\n",
       "      <td>1959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>316.101403</td>\n",
       "      <td>64</td>\n",
       "      <td>1959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>314.572166</td>\n",
       "      <td>65</td>\n",
       "      <td>1958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>315.270355</td>\n",
       "      <td>65</td>\n",
       "      <td>1958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>316.325380</td>\n",
       "      <td>65</td>\n",
       "      <td>1958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>284.001634</td>\n",
       "      <td>172</td>\n",
       "      <td>1851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>283.182872</td>\n",
       "      <td>178</td>\n",
       "      <td>1845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>283.531124</td>\n",
       "      <td>178</td>\n",
       "      <td>1845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>275.200000</td>\n",
       "      <td>409671</td>\n",
       "      <td>-407648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>274.200000</td>\n",
       "      <td>409671</td>\n",
       "      <td>-407648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        co2_ppmv  years_before_2023    year\n",
       "0     316.334020                 64    1959\n",
       "1     316.101403                 64    1959\n",
       "2     314.572166                 65    1958\n",
       "3     315.270355                 65    1958\n",
       "4     316.325380                 65    1958\n",
       "...          ...                ...     ...\n",
       "106   284.001634                172    1851\n",
       "109   283.182872                178    1845\n",
       "110   283.531124                178    1845\n",
       "1264  275.200000             409671 -407648\n",
       "1265  274.200000             409671 -407648\n",
       "\n",
       "[62 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat(g for _, g in ipcc_full_co2_data.groupby(\"years_before_2023\") if len(g) > 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duplicates are removed from the *years_before_2023* column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipcc_full_co2_data.drop_duplicates(subset='years_before_2023', keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the first five rows of the DataFrame confirms that the duplicate entries have been dropped from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>co2_ppmv</th>\n",
       "      <th>years_before_2023</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>316.334020</td>\n",
       "      <td>64</td>\n",
       "      <td>1959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>314.572166</td>\n",
       "      <td>65</td>\n",
       "      <td>1958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>315.342074</td>\n",
       "      <td>66</td>\n",
       "      <td>1957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>314.713961</td>\n",
       "      <td>68</td>\n",
       "      <td>1955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>313.171057</td>\n",
       "      <td>69</td>\n",
       "      <td>1954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     co2_ppmv  years_before_2023  year\n",
       "0  316.334020                 64  1959\n",
       "2  314.572166                 65  1958\n",
       "6  315.342074                 66  1957\n",
       "7  314.713961                 68  1955\n",
       "8  313.171057                 69  1954"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipcc_full_co2_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns are rearranged to be consistent with the *luthi_full_co2_data* DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipcc_full_co2_data = ipcc_full_co2_data.reindex(columns=['years_before_2023', 'year', 'co2_ppmv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>years_before_2023</th>\n",
       "      <th>year</th>\n",
       "      <th>co2_ppmv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>1959</td>\n",
       "      <td>316.334020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65</td>\n",
       "      <td>1958</td>\n",
       "      <td>314.572166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>66</td>\n",
       "      <td>1957</td>\n",
       "      <td>315.342074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>68</td>\n",
       "      <td>1955</td>\n",
       "      <td>314.713961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>69</td>\n",
       "      <td>1954</td>\n",
       "      <td>313.171057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   years_before_2023  year    co2_ppmv\n",
       "0                 64  1959  316.334020\n",
       "2                 65  1958  314.572166\n",
       "6                 66  1957  315.342074\n",
       "7                 68  1955  314.713961\n",
       "8                 69  1954  313.171057"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipcc_full_co2_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Mauna Loa CO2 Data <a id=\"mauna-loa-cO2-data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most recent CO2 dataset in a Comma Separated Value (CSV) file is available from from https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_annmean_mlo.csv. This dataset contains measurements of annual mean CO2 expressed as a mole fraction in dry air. The range of years in the dataset is from 1959 to 2022.\n",
    "\n",
    "Using Pandas the CSV file is read in as a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://gml.noaa.gov/ccgg/trends/data.html\n",
    "mauna_loa_co2 = pd.read_csv('https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_annmean_mlo.csv', skiprows=43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns in the dataset are renamed to logical names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code adapted from # https://sparkbyexamples.com/pandas/rename-columns-with-list-in-pandas-dataframe/\n",
    "cols = ['year', 'co2_ppmv', 'unc']\n",
    "\n",
    "mauna_loa_co2.columns = cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An unnecessary column is removed from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code adapted from https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html [Accessed 13 Dec. 2023]\n",
    "mauna_loa_co2.drop(['unc'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An additional column is added to the dataset that calculates the *year before the 2023*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mauna_loa_co2['years_before_2023'] = 2023 - mauna_loa_co2['year']\n",
    "\n",
    "# sort the data based on the year before present. Based on code from - https://saturncloud.io/blog/how-to-sort-pandas-dataframe-from-one-column/ [Accessed 13 Dec. 2023].\n",
    "mauna_loa_co2 = mauna_loa_co2.sort_values('years_before_2023')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns in the dataset are reordered and the first five rows of the DataFrame are checked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from code found here - https://practicaldatascience.co.uk/data-science/how-to-reorder-pandas-dataframe-columns [Accessed 13 Dec. 2023]\n",
    "mauna_loa_co2 = mauna_loa_co2.reindex(columns=['co2_ppmv', 'year', 'years_before_2023'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>co2_ppmv</th>\n",
       "      <th>year</th>\n",
       "      <th>years_before_2023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>418.53</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>416.41</td>\n",
       "      <td>2021</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>414.21</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>411.65</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>408.72</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    co2_ppmv  year  years_before_2023\n",
       "63    418.53  2022                  1\n",
       "62    416.41  2021                  2\n",
       "61    414.21  2020                  3\n",
       "60    411.65  2019                  4\n",
       "59    408.72  2018                  5"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mauna_loa_co2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DataFrame Dtypes are checked and are found to be consistent with the DataFrames containing CO2 data previously created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 64 entries, 63 to 0\n",
      "Data columns (total 3 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   co2_ppmv           64 non-null     float64\n",
      " 1   year               64 non-null     int64  \n",
      " 2   years_before_2023  64 non-null     int64  \n",
      "dtypes: float64(1), int64(2)\n",
      "memory usage: 2.0 KB\n"
     ]
    }
   ],
   "source": [
    "mauna_loa_co2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any rows with duplicate years are dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "mauna_loa_co2.drop_duplicates(subset='years_before_2023', keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The order of the columns is changes to be consistent with the other DataFrames containing CO2 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "mauna_loa_co2 = mauna_loa_co2.reindex(columns=['years_before_2023', 'year', 'co2_ppmv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>years_before_2023</th>\n",
       "      <th>year</th>\n",
       "      <th>co2_ppmv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>418.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>416.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>414.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>4</td>\n",
       "      <td>2019</td>\n",
       "      <td>411.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>5</td>\n",
       "      <td>2018</td>\n",
       "      <td>408.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    years_before_2023  year  co2_ppmv\n",
       "63                  1  2022    418.53\n",
       "62                  2  2021    416.41\n",
       "61                  3  2020    414.21\n",
       "60                  4  2019    411.65\n",
       "59                  5  2018    408.72"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mauna_loa_co2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Global Monthly CO2 Data 1979 - 2023 <a id=\"global-monthly-c02-data-1979---2023\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global monthly CO2 data from the NOAA is available from https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_mm_gl.txt (Accessed 23 Dec. 2023).\n",
    "\n",
    "This data is read in as a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_co2_data = pd.read_csv('datasets/historic/co2/co2_mm_gl.csv', skiprows=38)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first 5 rows of the dataset are inspected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>decimal</th>\n",
       "      <th>average</th>\n",
       "      <th>average_unc</th>\n",
       "      <th>trend</th>\n",
       "      <th>trend_unc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1979</td>\n",
       "      <td>1</td>\n",
       "      <td>1979.042</td>\n",
       "      <td>336.56</td>\n",
       "      <td>0.11</td>\n",
       "      <td>335.92</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1979</td>\n",
       "      <td>2</td>\n",
       "      <td>1979.125</td>\n",
       "      <td>337.29</td>\n",
       "      <td>0.09</td>\n",
       "      <td>336.25</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1979</td>\n",
       "      <td>3</td>\n",
       "      <td>1979.208</td>\n",
       "      <td>337.88</td>\n",
       "      <td>0.11</td>\n",
       "      <td>336.51</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1979</td>\n",
       "      <td>4</td>\n",
       "      <td>1979.292</td>\n",
       "      <td>338.32</td>\n",
       "      <td>0.12</td>\n",
       "      <td>336.72</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1979</td>\n",
       "      <td>5</td>\n",
       "      <td>1979.375</td>\n",
       "      <td>338.26</td>\n",
       "      <td>0.03</td>\n",
       "      <td>336.71</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>2023.375</td>\n",
       "      <td>420.54</td>\n",
       "      <td>0.10</td>\n",
       "      <td>418.87</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "      <td>2023.458</td>\n",
       "      <td>419.53</td>\n",
       "      <td>0.10</td>\n",
       "      <td>418.94</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "      <td>2023.542</td>\n",
       "      <td>417.83</td>\n",
       "      <td>0.10</td>\n",
       "      <td>419.10</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "      <td>2023.625</td>\n",
       "      <td>416.53</td>\n",
       "      <td>0.10</td>\n",
       "      <td>419.36</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>2023</td>\n",
       "      <td>9</td>\n",
       "      <td>2023.708</td>\n",
       "      <td>416.83</td>\n",
       "      <td>0.10</td>\n",
       "      <td>419.70</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>537 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     year  month   decimal  average  average_unc   trend  trend_unc\n",
       "0    1979      1  1979.042   336.56         0.11  335.92       0.09\n",
       "1    1979      2  1979.125   337.29         0.09  336.25       0.10\n",
       "2    1979      3  1979.208   337.88         0.11  336.51       0.10\n",
       "3    1979      4  1979.292   338.32         0.12  336.72       0.10\n",
       "4    1979      5  1979.375   338.26         0.03  336.71       0.10\n",
       "..    ...    ...       ...      ...          ...     ...        ...\n",
       "532  2023      5  2023.375   420.54         0.10  418.87       0.06\n",
       "533  2023      6  2023.458   419.53         0.10  418.94       0.06\n",
       "534  2023      7  2023.542   417.83         0.10  419.10       0.06\n",
       "535  2023      8  2023.625   416.53         0.10  419.36       0.06\n",
       "536  2023      9  2023.708   416.83         0.10  419.70       0.06\n",
       "\n",
       "[537 rows x 7 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthly_co2_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns that will not be used are dropped from the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_co2_data.drop(['decimal', 'average_unc', 'trend', 'trend_unc'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable Dtypes are checked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 537 entries, 0 to 536\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   year     537 non-null    int64  \n",
      " 1   month    537 non-null    int64  \n",
      " 2   average  537 non-null    float64\n",
      "dtypes: float64(1), int64(2)\n",
      "memory usage: 12.7 KB\n"
     ]
    }
   ],
   "source": [
    "monthly_co2_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values in the variables in the *year* and *month* columns are combined and appended to an empty list.  A *for loop* is used to iterate through every row in the DataFrame to complete this operation for every row in the DataFrame.\n",
    "\n",
    " The list is subsequently assigned to the DataFrame as the *date* column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from code found at \n",
    "# - https://stackoverflow.com/questions/48304927/cleanly-combine-year-and-month-columns-to-single-date-column-with-pandas \n",
    "# [Accessed 21 Dec. 2023].\n",
    "\n",
    "DATE = []\n",
    "for y, m in zip(monthly_co2_data.year, monthly_co2_data.month):\n",
    "    DATE.append(date(y, m, 1))\n",
    "    \n",
    "monthly_co2_data['date'] = DATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first five rows of the DataFrame are inspected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>average</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1979</td>\n",
       "      <td>1</td>\n",
       "      <td>336.56</td>\n",
       "      <td>1979-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1979</td>\n",
       "      <td>2</td>\n",
       "      <td>337.29</td>\n",
       "      <td>1979-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1979</td>\n",
       "      <td>3</td>\n",
       "      <td>337.88</td>\n",
       "      <td>1979-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1979</td>\n",
       "      <td>4</td>\n",
       "      <td>338.32</td>\n",
       "      <td>1979-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1979</td>\n",
       "      <td>5</td>\n",
       "      <td>338.26</td>\n",
       "      <td>1979-05-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  average        date\n",
       "0  1979      1   336.56  1979-01-01\n",
       "1  1979      2   337.29  1979-02-01\n",
       "2  1979      3   337.88  1979-03-01\n",
       "3  1979      4   338.32  1979-04-01\n",
       "4  1979      5   338.26  1979-05-01"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthly_co2_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *date* column is set as the DataFrame index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_co2_data = monthly_co2_data.set_index('date').asfreq('MS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This operation is validated by visually checking the first five rows of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1979-01-01</th>\n",
       "      <td>1979</td>\n",
       "      <td>1</td>\n",
       "      <td>336.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-02-01</th>\n",
       "      <td>1979</td>\n",
       "      <td>2</td>\n",
       "      <td>337.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-03-01</th>\n",
       "      <td>1979</td>\n",
       "      <td>3</td>\n",
       "      <td>337.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-04-01</th>\n",
       "      <td>1979</td>\n",
       "      <td>4</td>\n",
       "      <td>338.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-05-01</th>\n",
       "      <td>1979</td>\n",
       "      <td>5</td>\n",
       "      <td>338.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-01</th>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>420.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-01</th>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "      <td>419.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-01</th>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "      <td>417.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01</th>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "      <td>416.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-01</th>\n",
       "      <td>2023</td>\n",
       "      <td>9</td>\n",
       "      <td>416.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>537 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            year  month  average\n",
       "date                            \n",
       "1979-01-01  1979      1   336.56\n",
       "1979-02-01  1979      2   337.29\n",
       "1979-03-01  1979      3   337.88\n",
       "1979-04-01  1979      4   338.32\n",
       "1979-05-01  1979      5   338.26\n",
       "...          ...    ...      ...\n",
       "2023-05-01  2023      5   420.54\n",
       "2023-06-01  2023      6   419.53\n",
       "2023-07-01  2023      7   417.83\n",
       "2023-08-01  2023      8   416.53\n",
       "2023-09-01  2023      9   416.83\n",
       "\n",
       "[537 rows x 3 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthly_co2_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature Data <a id=\"temperature-data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jouzel (2007) Temperature Data <a id=\"jouzel-(2007)-temperature-data\"></a>\n",
    "\n",
    "Data from Jouzel et al (2007) is from a high-resolution deuterium profile from European Project for Ice Coring in Antarctica (EPICA) Dome C ice core. As per the metadata available for this data set, available from [here](https://doi.pangaea.de/10.1594/PANGAEA.683655) (https://doi.pangaea.de/10.1594/PANGAEA.683655), temperature was estimated after correction for sea-water isotopic composition (Bintanja, van de Wal and Oerlemans, 2005) and for ice sheet elevation on EDC3 age scale (Parrenin et al, 2007). The EDC3 age scale is discussed further [here](#carbon-dioxide).\n",
    "\n",
    "The dataset is read into a Pandas DataFrame using Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jouzel_temp = pd.read_csv('epicaDC.deuttemp.EDC3-AICC.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *jouzel_temp* DataFrame is explored to understand the data in the dataset. The first and last 5 rows of the DatFrame are printed. From visualising this information the dataset appears to consist of seven variables. There appears to be a *temp* variable that is in Kelvin. Two variables that describe a chronology for the temperature value - *EDC3* and *AICC2012*. The systems are discussed in further detail [here](#carbon-dioxide).\n",
    "\n",
    "From the data in this dataset it should be possible to calculate the year when the corresponding temperature measurement was taken. Once this is known a temperature anomaly value can be calculated.\n",
    "\n",
    "Temperature anomaly is defined as:\n",
    "\n",
    "*\"The term temperature anomaly means a departure from a reference value or long-term average. A positive anomaly indicates that the observed temperature was warmer than the reference value, while a negative anomaly indicates that the observed temperature was cooler than the reference value.\"* (www.ncei.noaa.gov, n.d.).\n",
    "\n",
    "From the Jouzel dataset the following measurements can be calculated:\n",
    "\n",
    "+ age of a sample\n",
    "\n",
    "+ temperature value in degrees celsius of the sample\n",
    "\n",
    "+ temperature anomaly for a desired period of the sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the first five rows of data\n",
    "jouzel_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jouzel_temp.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pandas data types can be understood by using the `info()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jouzel_temp.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NOAA temperature data explored in the next [section](#noaa-temperature-data) is a subset of this data using the EDC3 chronology with a temperature anomaly calculated as the temperature difference from the average of the last 1000 years.\n",
    "\n",
    "It should therefore be possible to create a subset of this data for the AICC2012 chronology with a temperature anomaly  calculated as the temperature difference from the average of the last 1000 years.\n",
    "\n",
    "Firstly, unnecessary columns are dropped from DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jouzel_temp.drop(['bag', 'ztop', 'deutfinal', 'acc-EDC3beta'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A column to convert Kelvin to celsius is added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jouzel_temp['celsius'] = jouzel_temp['temp'] - 273.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean temperature for approximately the last 1000 years is assigned to a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average = jouzel_temp['celsius'][0:87].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The temperature anomaly in celsius is calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jouzel_temp['anomaly'] = jouzel_temp['celsius'] - average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A column to calculate the years from present is added to the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate years before present aicc2012 chronology\n",
    "jouzel_temp['aicc2012_years_before_2023'] = 2023 - (1950 - jouzel_temp['AICC2012'])\n",
    "\n",
    "# calculate years before present EDC3 chronology\n",
    "jouzel_temp['edc3_years_before_2023'] = 2023 - (1950 - jouzel_temp['EDC3béta'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DataFrame is printed to validate the calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jouzel_temp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DataFrame Pandas Dtypes are explored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jouzel_temp.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *years_before_2023* variables are converted to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jouzel_temp = jouzel_temp.astype({'aicc2012_years_before_2023':'int', 'edc3_years_before_2023':'int'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jouzel_temp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jouzel_temp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any rows with duplicate years are dropped from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jouzel_temp.drop_duplicates(subset='aicc2012_years_before_2023', keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jouzel_temp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOAA Temperature Data <a id=\"noaa-temperature-data\"></a>\n",
    "\n",
    "The NOAA is the National Oceanic and Atmospheric Administration. More information on this organisation is available from [here](https://www.noaa.gov/) (https://www.noaa.gov/).\n",
    "\n",
    "Upon exploration of the NOAA temperature dataset it is apparent the temperature data from the NOAA is essentially a subset of data from Jouzel et al (2007) that has been processed to calculate degrees celsius temperature anomaly. As per the metadeta for the sample, availalbe [here](https://doi.pangaea.de/10.1594/PANGAEA.683655) (https://doi.pangaea.de/10.1594/PANGAEA.683655), the core samples in the dataset have been aged using the EDC3 chronology, discussed further [here](#analysis).\n",
    "\n",
    "As per the metadata for this dataset the temperature anomaly is calculated as the temperature difference from the average of the last 1000 years.\n",
    "\n",
    "The data in this is from the year 2000 AD to approximately 800,000 years ago.\n",
    "\n",
    "Temperature data from the NOAA is read in as a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/27896214/reading-tab-delimited-file-with-pandas-works-on-windows-but-not-on-mac\n",
    "\n",
    "noaa_temp = pd.read_csv('https://doi.pangaea.de/10.1594/PANGAEA.683655?format=textfile', sep=\"\\t\", skiprows=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noaa_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noaa_temp.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns are renamed to logical names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noaa_temp.rename(columns=({\"Depth ice/snow [m]\":\"depth_ice_snow_m\", \"Age model [ka]\":\"age_model_ka\", \"δD [‰ SMOW]\":\"δd_‰_smow\", \"delta T [°C]\":\"delta_t_c\", \"Sample ID\":\"sample_id\"}), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noaa_temp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns are added to calculate the year and the year before 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noaa_temp['years_before_2023'] = 2023 - (1950-(noaa_temp['age_model_ka']*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noaa_temp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Dtypes in the *noaa_temp* DataFrame are explored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noaa_temp.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *years_before_2023* variable is cast from a float to an integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noaa_temp = noaa_temp.astype({'years_before_2023':'int'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noaa_temp.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand if the transform that was applied to the Jouzel temperature dataset matches the above dataset they are plotted against one another.\n",
    "\n",
    "As can be seen the manually transformed dataset does not cancel out the data from the NOAA. For the first 400,000 they are very closely matched. After this the temperature anonalies differ as does the time scales which suggests that before 400,000 years ago the data is somehow processed differntly by the NOAA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty plot\n",
    "fig, ax = plt.subplots(figsize=(15, 10 ))\n",
    "\n",
    "# plot the results\n",
    "ax.plot(jouzel_temp['edc3_years_before_2023'], jouzel_temp['anomaly'], label = 'Manually Transformed EDC3 Temp Data')\n",
    "\n",
    "# adapted from code found here - https://www.geeksforgeeks.org/change-the-line-opacity-in-matplotlib/ [Accessed 19 Dec. 2023]\n",
    "ax.plot(noaa_temp['years_before_2023'], noaa_temp['delta_t_c'], label = 'Anomaly as per NOAA EDC3 Chronology', color = 'black', alpha = 0.6)\n",
    "ax.set_xlabel('Years Before 2023')\n",
    "ax.set_ylabel('Temperature Anomaly Degrees Celsius')\n",
    "\n",
    "ax.legend()\n",
    "ax.set_title('EDC 2023 Manual Anomaly Calculation Vs NOAA Calculation', weight ='bold', size=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Further Temperature Data <a id=\"further-temperature-data\"></a>\n",
    "\n",
    "A further set of historic temperature data can be created from numerous other data sources. \n",
    "\n",
    "The temperature from from 1880 to 2022 in this dataset is sourced from [NASA](https://data.giss.nasa.gov/gistemp/graphs/graph_data/Global_Mean_Estimates_based_on_Land_and_Ocean_Data/graph.txt) (https://data.giss.nasa.gov/gistemp/graphs/graph_data/Global_Mean_Estimates_based_on_Land_and_Ocean_Data/graph.txt [Accessed 12 Dec. 2023].). [1] The temperature data is the global surface temperature.\n",
    "\n",
    "Temperature data from 1880 to 800k years from the 2023 was sourced from [https://www.temperaturerecord.org/#sources](https://www.temperaturerecord.org/#sources) accessed 13 Dec. 2023. [2] & [3]. \n",
    "\n",
    "Data ranging rom 2000 to 20,000 years ago reconstructed by averaging well-dated, calibrated proxy temperature records from around the world, mostly from ocean margin sediment cores, in addition to lake and ice cores on land.\n",
    "\n",
    "Data from 20,000 to 800,000 years ago is reconstructed by taking a spatially-weighted average of 59 proxy sea surface temperature records from around the global oceans.\n",
    "\n",
    "Data from 2000 to 800,000 years ago has been scaled to have a glacial-interglacial range of 4°C based on more comprehensive datasets suggesting that this was the likely magnitude of ice age cooling (Annan and Hargreaves, 2013, Climate of the Past). \n",
    "\n",
    "All of the temperature data is compared to the long-term average from 1951 to 1980. Therefore this temperature data uses a different anomaly to the NOAA data and should have different plots when compared to each other.\n",
    "\n",
    "[1] Credits - Snyder, C.W. 2016.\n",
    "\n",
    "[2] Credits - Marcott et al, 2013\n",
    "\n",
    "[3] Credits - Shakun et al, 2012\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Pandas modern temperature data is read in from the NASA website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasa_temp = pd.read_csv(\n",
    "    'https://data.giss.nasa.gov/gistemp/graphs/graph_data/Global_Mean_Estimates_based_on_Land_and_Ocean_Data/graph.txt', \n",
    "    skiprows=5, header=None, sep = ' ', skipinitialspace=True, engine='python', names=['year', 'temp_anomaly', 'lowness'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An unnecessary column is dropped from the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasa_temp.drop(['lowness'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A column with the year before present is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasa_temp['years_before_2023'] = 2023 - nasa_temp['year']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remaining columns are renamed to a standard naming convention that will be used with temperature data from another source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasa_temp = nasa_temp.reindex(columns=['year', 'years_before_2023', 'temp_anomaly'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NASA data is sorted by year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasa_temp = nasa_temp.sort_values('year', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasa_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre 1800's temperature data is read in from worksheets in an excel spreadsheet that contains all of the historic temperature data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moberg_temp = pd.read_excel('temperature_dataset.xlsx', \n",
    "                            sheet_name='2,000 yr',  names=['year', 'yr_bp', 'temp_anomaly', 'x', 'y', 'z'])\n",
    "clark_temp = pd.read_excel('temperature_dataset.xlsx', \n",
    "                           sheet_name='20,000 yr', names=['yr_bp', 'temp_anomaly', 'x', 'y', 'z'])\n",
    "shakun_temp = pd.read_excel('temperature_dataset.xlsx', \n",
    "                            sheet_name='800,000 yr', names=['yr_bp', 'temp_anomaly', 'x', 'y', 'z'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unneeded columns are removed from the DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remaining columns are re-ordered to make them consistent with the rest of the temperature DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moberg_temp.drop(moberg_temp.index[0:100], axis = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unneeded *year* column is dropped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moberg_temp.drop('year', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A number of precessing tasks are grouped together in a function. The `temp_year()` function removes unneeded columns from the DataFrame and adds a column to calculate the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp_year(sample):\n",
    "    sample.drop(['x', 'y', 'z'],axis=1, inplace=True)\n",
    "    sample['year'] = 1950-sample['yr_bp']\n",
    "    sample['years_before_2023'] = 2023 - sample['year']\n",
    "    sample.drop(['yr_bp'],axis=1, inplace=True)\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a for loop the relevant datasets are paased to the `temp_year()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [moberg_temp, clark_temp, shakun_temp]\n",
    "\n",
    "for sample in samples: temp_year(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rows are dropped from each of the  DataFrames so that there is no overlap between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clark_temp.drop(clark_temp.index[0:19], axis = 0, inplace = True)\n",
    "shakun_temp.drop(shakun_temp.index[0:7], axis = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moberg_temp = moberg_temp.reindex(columns=['year', 'years_before_2023', 'temp_anomaly'])\n",
    "clark_temp = clark_temp.reindex(columns=['year', 'years_before_2023', 'temp_anomaly'])\n",
    "shakun_temp = shakun_temp.reindex(columns=['year', 'years_before_2023', 'temp_anomaly'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the temperature DataFrames are concatenated to give a composite record of the temperature anomaly over the last 800k years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_temp = [nasa_temp, moberg_temp, clark_temp, shakun_temp]\n",
    "\n",
    "full_temp_data = pd.concat(frames_temp, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable Dtypes are checked in the *full_temp_data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_temp_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duplicate year entries are removed from the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_temp_data.drop_duplicates(subset='years_before_2023', keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_temp_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monthly Temperature Data <a id=\"monthly-temperature-data\"></a>\n",
    "\n",
    "Monthly global temperature anomaly temperature data was sourced from https://datahub.io/core/global-temp#readme (Accessed 28 Dec. 2023). The source of the data focused on is GISTEMP: NASA Goddard Institute for Space Studies (GISS) Surface Temperature Analysis, Global Land-Ocean Temperature Index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the dataset as a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_temperature_data = pd.read_csv('https://datahub.io/core/global-temp/r/monthly.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter to show only data from GISTEMP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "monthly_temperature_data = monthly_temperature_data[monthly_temperature_data['Source'] == 'GISTEMP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_temperature_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_temperature_data.sort_index(ascending=False, inplace=True)\n",
    "\n",
    "monthly_temperature_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop *Source* column as it is not needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insoect the DataFrame variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_temperature_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Covert the *Date* variable to a Pandas *datetime* Dtype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.date_range(start='12/06/1879', end='12/12/2016', freq='MS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_temp_data = pd.DataFrame({'mean':monthly_temperature_data['Mean'].values}, index=dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_temp_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methane Data <a id=\"methane-data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A composite record of historic methane data can be formed taking dats from multiple sources.\n",
    "\n",
    "Methane data from 2023 to 1984 is obtained from the NOAA.\n",
    "\n",
    "Methane data from 1982 to 1888 was sourced from the NOAA (Etheridge, Steele, Francey, and Langenfelds, 1998).\n",
    "\n",
    "Methane data from from 1884 to 800,000 previous was sourced from the EPICA Dome C Ice Core dataset (Loulergue et al., 2008).\n",
    "\n",
    "Methane levels are measured as CH4 mean (ppbv)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methane data is read into Pandas DataFrames from the respective data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methane_1 = pd.read_table('ch4_annmean_gl.txt', skiprows=45, sep=' ')\n",
    "methane_2 = pd.read_table('law_ch4.txt', \n",
    "                        sep='\\t', skiprows = 647, encoding='unicode_escape', names = ['year', 'ch4_ppb', 'Unnamed: 2', \n",
    "                                                                                      'Unnamed: 3', 'Unnamed: 4', '64'])\n",
    "methane_3 = pd.read_table('law_ch4.txt', \n",
    "                        sep='\\t', skiprows = 155, nrows=15, encoding='unicode_escape', \n",
    "                        names=['year', 'ch4_ppb', '4', '5', '6', '7'])\n",
    "methane_4 = pd.read_table('https://www1.ncdc.noaa.gov/pub/data/paleo/icecore/antarctica/epica_domec/edc-ch4-2008.txt', \n",
    "                          sep = ' ', skipinitialspace=True, skiprows = 155, \n",
    "                          names=['depth', 'yr_bp', 'ch4_ppb', '4', '5', '6', '7'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unnecessary columns are removed from the respective DataFrames. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methane_1.drop(['#', 'year', 'Unnamed: 3', 'Unnamed: 5', 'mean', 'Unnamed: 7', 'Unnamed: 8', \n",
    "                'Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11', 'unc'], axis=1, inplace=True)\n",
    "methane_2.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', '64'], axis=1, inplace=True)\n",
    "methane_3.drop(['4', '5', '6', '7'], axis=1, inplace=True)\n",
    "methane_4.drop(['depth', '4', '5', '6', '7'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns in *methane_1* are renamed to logical names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['year', 'ch4_ppb']\n",
    "methane_1.columns = cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a year column and calculate the year for the *methane_4* DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methane_4['year'] = 1950 - methane_4['yr_bp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Years before present* columns are created in each of the DataFrames to calculate the number of years before 2023 that the samples are from. This is achieved by defining a function and passing the DatFrames to the function via a for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def years_before_present(sample):\n",
    "    sample['years_before_2023'] = 2023 - sample['year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methane_1 = methane_1.sort_values('year', ascending=False)\n",
    "methane_2 = methane_2.sort_values('year', ascending=False)\n",
    "methane_3 = methane_3.sort_values('year', ascending=False)\n",
    "methane_4 = methane_4.sort_values('year', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = [methane_1, methane_2, methane_3, methane_4]\n",
    "\n",
    "for set in sets: years_before_present(set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methane_4 = methane_4.reindex(columns=['year', 'ch4_ppb', 'years_before_2023', 'yr_bp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_methane = [methane_1, methane_2, methane_3, methane_4]\n",
    "\n",
    "full_methane_data = pd.concat(frames_methane, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_methane_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unneeded yr_bp column is dropped from the *full_temp* DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_methane_data.drop('yr_bp', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns in the DataFrame are reordered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_methane_data = full_methane_data.reindex(columns=['years_before_2023', 'year', 'ch4_ppb'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duplicate *year* variable entries are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_methane_data.drop_duplicates(subset='years_before_2023', keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NA values are dropped from the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_methane_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable Dtypes are explored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_methane_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The year variables are cast to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_methane_data = full_methane_data.astype({'year':'int', 'years_before_2023':'int'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_methane_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_methane_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Irish Data <a id=\"irish_data\"></a>\n",
    "\n",
    "Historic Irish temperature and observed precipitation data was sourced from the [World Bank Group](https://climateknowledgeportal.worldbank.org/) (https://climateknowledgeportal.worldbank.org/ Accessed 20 Dec. 2023) website who sourced their [data](https://climateknowledgeportal.worldbank.org/country/ireland/climate-data-historica) (https://climateknowledgeportal.worldbank.org/country/ireland/climate-data-historical Accessed 20 Dec. 2023) from  the climate research unit in the University of East Anglia (https://www.uea.ac.uk/groups-and-centres/climatic-research-unit Accessed 20 Dec. 2023).\n",
    "\n",
    "A monthly data set of weather observations from Dublin Airport for the period of 1942 to 2003 was obatined from [Met Eireann](https://www.met.ie/about-us) (https://www.met.ie/about-us). This data was sourced from [here](https://www.met.ie/climate/available-data/historical-data) (https://www.met.ie/climate/available-data/historical-data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Irish Temperature Data <a id=\"irish_temperature_data\"></a>\n",
    "\n",
    "Read in historic Irish annnual mean temperature data and view the first five lines of the dataset to get an overview  the variables in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irish_temp_data = pd.read_csv('observed_annual_average_mean_surface_air_temperature_of_ireland_for_1901_2022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irish_temp_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns in the dataset are renamed to Python friendly names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irish_temp_data.rename(columns={'Category': 'year', 'Annual Mean': 'annual_mean', '5-yr smooth': '5_yr_smooth'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data types are understood using the Pandas `info()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irish_temp_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a time series using the year as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html [Accessed 7 Nov. 2023]\n",
    "irish_temp_data['time_series'] = pd.to_datetime(irish_temp_data['year'], format='%Y')\n",
    "\n",
    "# set time_series column as index\n",
    "# https://stackoverflow.com/questions/27032052/how-do-i-properly-set-the-datetimeindex-for-a-pandas-datetime-object-in-a-datafr\n",
    "# [Accessed 7 Nov. 2023].\n",
    "irish_temp_data = irish_temp_data.set_index('time_series')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A column is added to calculate the median of the *annual_mean* variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irish_temp_data['median'] = irish_temp_data['annual_mean'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irish_temp_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in monthly Irish weather data from Dublin Airport as a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_monthly_weather_data = pd.read_csv('mly532.csv', skiprows = 19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the first five rows of the DataFrame to get an overview. The month and year variables are in separate columns. To create a time series these to variables need to be combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_monthly_weather_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To combine the year and month variables they are appended to a list and added into the DataFrame in the *date* column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from code found at \n",
    "# - https://stackoverflow.com/questions/48304927/cleanly-combine-year-and-month-columns-to-single-date-column-with-pandas \n",
    "# [Accessed 21 Dec. 2023].\n",
    "\n",
    "DATE = []\n",
    "for y, m in zip(da_monthly_weather_data.year, da_monthly_weather_data.month):\n",
    "    DATE.append(date(y, m, 1))\n",
    "    \n",
    "da_monthly_weather_data['date'] = DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_monthly_weather_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_monthly_weather_data['time_series'] = pd.to_datetime(da_monthly_weather_data['date'], format='%d/%m/%Y')\n",
    "\n",
    "da_monthly_weather_data = da_monthly_weather_data.set_index('time_series')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_monthly_weather_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Irish Precipitation Data <a id=\"irish_temperature_data\"></a>\n",
    "\n",
    "Historic Irish precipitation data from the [World Bank Group](https://climateknowledgeportal.worldbank.org/) (https://climateknowledgeportal.worldbank.org/ Accessed 20 Dec. 2023) is read in as a Pandas DataFrame. This data gives an overview of the trend in precipitation lecvels from 1900 to 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irish_precip_data = pd.read_csv('observed_annual_precipitation_of_ireland_for_1901_2022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irish_precip_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column names are renamed to python friendly names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irish_precip_data.rename(columns={'Category': 'year', 'Annual Mean': 'annual_mean', '5-yr smooth': '5_yr_smooth'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables datatypes are explored using the Pandas `info()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irish_precip_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A time series is created using the year as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html [Accessed 7 Nov. 2023]\n",
    "irish_precip_data['time_series'] = pd.to_datetime(irish_precip_data['year'], format='%Y')\n",
    "\n",
    "# set time_series column as index\n",
    "# https://stackoverflow.com/questions/27032052/how-do-i-properly-set-the-datetimeindex-for-a-pandas-datetime-object-in-a-datafr \n",
    "# [Accessed 7 Nov. 2023].\n",
    "irish_precip_data = irish_precip_data.set_index('time_series')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irish_precip_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Historical monthly precipitation data from 1711 to 2016 is read in as a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irish_monthly_precip_data = pd.read_csv('IOI_1711_SERIES.CSV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irish_monthly_precip_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns are renamed to python friendly names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irish_monthly_precip_data.rename(columns={'Year': 'year', 'Month': 'month', 'Median montly series': 'median_monthly_precip_mm'},\n",
    "                                  inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irish_monthly_precip_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The month and year columns are merged so that a time series can be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE = []\n",
    "for y, m in zip(irish_monthly_precip_data.year, irish_monthly_precip_data.month):\n",
    "    DATE.append(date(y, m, 1))\n",
    "    \n",
    "irish_monthly_precip_data['date'] = DATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A time series is set as the index of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irish_monthly_precip_data['time_series'] = pd.to_datetime(irish_monthly_precip_data['date'], format='%d/%m/%Y')\n",
    "\n",
    "irish_monthly_precip_data = irish_monthly_precip_data.set_index('time_series')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fused Dataset <a id=\"fused_dataset\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fused dataset consisting of historical carbon dioxide, temperature and methane levels can be created by merging the DataFrames containing these variables these into one Pandas DataFrame. In order to do this the relevant data must be selected.\n",
    "\n",
    "For historical temperature data the IPCC dataset will be used as it uses the AICC2012 system to date the carbon dioxide samples in the dataset. The AICC2012 system is expanded upon in the [analysis](#analysis) section of this notebook. The reason for selecting this is that it said to provide an improved timing for the bipolar nature of the interglacial periods.\n",
    "\n",
    "Temperature data from the NOAA is dated using the EDC3 system. If this was used with the carbon dioxide data from the IPCC there would be a mismatch between the timings of the samples as these two systems are not in agreement with each other as to the age of the ice core samples. This is demonstrated in the [analysis](#analysis) section by plotting two sets of carbon dioxide that have been aged using each of these systems. As [demonstrated](#carbon-dioxide) the trends on the graphs are nearly identical but the timings of the data points are out of step with each other. For this reason temperature data that was sourced from [NASA](https://data.giss.nasa.gov/gistemp/graphs/graph_data/Global_Mean_Estimates_based_on_Land_and_Ocean_Data/graph.txt) (https://data.giss.nasa.gov/gistemp/graphs/graph_data/Global_Mean_Estimates_based_on_Land_and_Ocean_Data/graph.txt [Accessed 12 Dec. 2023]) and [https://www.temperaturerecord.org/#sources](https://www.temperaturerecord.org/#sources), accessed 13 Dec. 2023 is used in the fused dataset.\n",
    "\n",
    "Finally the methane data from [here](#methane-data) is used in the fused dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IPCC carbon dioxide data is concatenated to the most recent co2 data from the Mauna Loa observatory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [mauna_loa_co2, ipcc_full_co2_data]\n",
    "\n",
    "full_co2_data = pd.concat(frames, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_co2_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting the DataFrame it can be seen that the *year* and *years_before_2023* variables are integers and the *co2_ppmv* variables is a floating point integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_co2_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full carbon dioxide dataset is merged into the full temperature dataset on the *year* variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code adapted from https://stackoverflow.com/questions/53645882/pandas-merging-101 [Accessed 18 Dec. 2023]\n",
    "fused_data = full_co2_data.merge(full_temp_data, on = 'years_before_2023', how = 'outer') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fused_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further operations are carried out on the fused dataset to remove unnecessary columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fused_data.drop(['year_x', 'year_y'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duplicates are checked in the *fused_data* DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(g for _, g in fused_data.groupby(\"years_before_2023\") if len(g) > 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The single duplicate value is dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fused_data.drop_duplicates(subset='years_before_2023', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is sorted by descending year and the ordering of the columns is changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fused_data = fused_data.sort_values('years_before_2023', ascending=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full methane dataset variables are checked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_methane_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *full methane data* DataFrame is merged into the *fused_data* DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fused_data = fused_data.merge(full_methane_data, on='years_before_2023', how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data in the *fused data* DataFrame is sorted by descending year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fused_data = fused_data.sort_values('years_before_2023', ascending=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unnecessary year column is dropped from the *fused_data* DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fused_data.drop('year', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fused_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fused_data.interpolate(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fused_data.to_excel('fused.data.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring the variables in the *fused_data* demonstrates that there are 5 vairiables in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fused_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables can be summarised as follows:\n",
    "\n",
    "Applying variable classification and level of measurement the dataset can be summarised as follows:\n",
    "\n",
    "**Fused Dataset Variable Summary Table**\n",
    "\n",
    "| Variable              | Classification    | Type          | Python Dtype  | Unit of Measure                                           | Level of Measure  |\n",
    "| :----------           | :----------       | :----------   | :----------   | :---------                                                |:--------          |\n",
    "| year                  | numerical         | interval      | int64         | year                                                      | interval          |\n",
    "| co2_ppmv              | numerical         | continuous    | float64       | parts per million by volume                               | ratio             |\n",
    "| temp_anomaly          | numerical         | continuous    | float64       | degrees celsius                                           | interval          |\n",
    "| ch4_ppb               | numerical         | continuous    | float64       | mole fraction in dry air, nanomol/mol, abbreviated as ppb | ratio             |\n",
    "| years_before_present  | numerical         | interval      | int64         | degrees celcius                                           | interval          |\n",
    "\n",
    "There will be null values in the fused dataset due to the fact that the dates the measurements are aged to do not always match.\n",
    "\n",
    "Checking the null values confirms this. It is important that the *year* and *years_before_present* variables do not have any null values as this confirms that there is at least one data entry for the other variables in each row of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fused_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_corr = fused_data.corr(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(fd_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis <a id=\"analysis\"></a>\n",
    "\n",
    "### Carbon Dioxide <a id=\"carbon_dioxide\"></a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A composite of the IPCC data is plotted. This plot demonstrates approximately 800,000 years of co2 data. The composite graph demonstrates how the results from each study have been stitched together to form a cohesive narrative on the fluctuations of  carbon dioxide levels over the last 800,000 years. The plot demonstrates peaks and lows of carbon dioxide approximately every 100,000 years. This aligns with glacial-interglacial cycles occurring every 100,000 years since the Quaternary period (Lisiecki and Raymo, 2005).) During these periods, as polar ice caps melt carbon dioxide is released into the atmosphere thus causing the the rise in atmospheric carbon dioxide.\n",
    "\n",
    "A rapid rise in carbon dioxide levels during the 21st century is observed. This rise is greater and more rapid than can be accounted for by the glacial-interglacial cycle and is attributed to the post industrial revolution large scale usage of fossil fuels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty plot\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "\n",
    "# plot the composite graph with labelling and titles\n",
    "ax.plot(rubino['years_before_2023'], rubino['co2_ppmv'], label='Law Dome (Rubino et al., 2013)')\n",
    "ax.plot(macfarling['years_before_2023'], macfarling['co2_ppmv'], label = 'Law Dome (MacFarling Meure et al., 2006)')\n",
    "ax.plot(monnin['years_before_2023'], monnin['co2_ppmv'], label = 'Dome C (Monnin et al., 2001 + 2004)')\n",
    "ax.plot(marcott['years_before_2023'], marcott['co2_ppmv'], label = 'WAIS (Marcott et al., 2014)')\n",
    "ax.plot(ahn['years_before_2023'], ahn['co2_ppmv'], label = 'Siple Dome (Ahn et al., 2014)')\n",
    "ax.plot(bereiter['years_before_2023'], bereiter['co2_ppmv'], label = 'TALDICE (Bereiter et al., 2012)')\n",
    "ax.plot(bereiter_2['years_before_2023'], bereiter_2['co2_ppmv'], label  = 'EDML (Bereiter et al., 2012)')\n",
    "ax.plot(schneider['years_before_2023'], schneider['co2_ppmv'], label = 'Dome C Sublimation (Schneider et al., 2013)')\n",
    "ax.plot(petit['years_before_2023'], petit['co2_ppmv'], label = 'Vostok (Petit et al., 1999)')\n",
    "ax.plot(siegenthaler['years_before_2023'], siegenthaler['co2_ppmv'], label = 'Dome C (Siegenthaler et al., 2005)')\n",
    "ax.plot(siegenthaler_2['years_before_2023'], siegenthaler_2['co2_ppmv'], label = 'Dome C (Siegenthaler et al., 2005)')\n",
    "ax.plot(bereiter_3['years_before_2023'], bereiter_3['co2_ppmv'], label = 'Dome C (Bereiter et al., 2014)')\n",
    "ax.set_xlabel('Years Before 2023')\n",
    "ax.set_ylabel('c02 PPM')\n",
    "ax.legend()\n",
    "plt.suptitle(\"IPCC - 800k Years of co2\", weight = 'bold', size = 15)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The composite of the Luthi et al subsets of data is plotted in the same way as the IPCC composite data. An immediate observation is that the data is not as well joined as the data in the IPCC. This is observed at the intersection between Dome C Siegenthaler and Dome C Luthi. The intersections of the subsets of data in the IPCC set are joined less crudely than Luthi. Another noticeable observation is that the large spike in carbon dioxide from the modern era is not observed in Luthi's dataset, most likely as the first data point is in 1813, before the widespread usage of fossil fuels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty plot\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "\n",
    "# plot the composite graph with labelling and titles\n",
    "ax.plot(monnin_luthi['years_before_2023'], monnin_luthi['co2_ppmv'], label='Dome C (Monnin et al. 2001)')\n",
    "ax.plot(pettit_luthi['years_before_2023'], pettit_luthi['co2_ppmv'], label = 'Vostok (Petit et al. 1999; Pepin et al. 2001; Raynaud et al. 2005)')\n",
    "ax.plot(siegenthaler_1_luthi['years_before_2023'], siegenthaler_1_luthi['co2_ppmv'], label = 'Dome C (Siegenthaler et al. 2005)')\n",
    "ax.plot(siegenthaler_2_luthi['years_before_2023'], siegenthaler_2_luthi['co2_ppmv'], label = 'Dome C (Siegenthaler et al. 2005)')\n",
    "ax.plot(luthi_luthi['years_before_2023'], luthi_luthi['co2_ppmv'], label = 'Siple Dome (Dome C (Luethi et al. (sub)')\n",
    "ax.set_xlabel('Years Before Present')\n",
    "ax.set_ylabel('c02 PPM')\n",
    "ax.legend()\n",
    "plt.suptitle(\"Luthi - 800k Years of co2\", weight = 'bold', size = 15)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting both carbon dioxide datasets over one another on the same axis allows for a direct comparison.\n",
    "\n",
    "The most noticeable feature is that the two plots create a blurred appearance as if they are slightly out of phase with one another.\n",
    "\n",
    "The IPCC data uses the The Antarctic Ice Core Chronology (AICC2012) (Veres et al, 2013) system to age carbon dioxide samples. The data in Luthi dataset uses the EDC3 chronology (Parrenin et al., 2007). The use of two different systems to data the same ice core samples would account for the discrepancy in datapoints that have the same co2 ppm concentration but are slightly out of synchronisation in terms of the time from present when the datapoints fall.\n",
    "\n",
    "The difference between the two systems is that the AICC2012 timescale has been constructed using the Bayesian tool Datice (Lemieux-Dudon et al., 2010). The Datice tool combines glaciological inputs and data constraints. Whereas the EDC3 timescale is based on the use of a snow accumulation and mechanical flow model and a set a set of independent age markers along the core (Parrenin et al, 2007).\n",
    "\n",
    "AICC2012 is said to present an improved timing for the last glacial inception and presents a slightly improved timing for the bipolar sequence of events over Marine Isotope Stage 3 (Bazin et al., 2013). Given the see saw nature of glacial-interglacial periods this suggests that the AICC2012 provides a better resolution on the age of samples.\n",
    "\n",
    "Basin et al (op. cit.) found that the biggest deviation between AICC2012 and EDC occurs around Marine Isotope Stage 12 (MIS 12) approximately 478K years ago. This is not apparent on the plot below. It appears that there is a noticeably bigger deviation between 350,000 - 400,00 years ago.\n",
    "\n",
    "Some parts of the respective plots cancel each other out (from approximately 600,000-700,00 years ago) suggesting very little disparity between the two chronological systems for samples that fall in that age range.\n",
    "\n",
    "Apart from the period of approximately 20,00 years ago to 100,000 years ago the trends over time on the two datasets closely match one another. \n",
    "\n",
    "It can be said that both datasets are largely in agreement over the trends in atmospheric carbon dioxide over time but that there is disagreement over when these fluctuations occurred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "\n",
    "ax.plot(ipcc_full_co2_data['years_before_2023'], ipcc_full_co2_data['co2_ppmv'], label = 'IPCC 800k Years of co2 Data')\n",
    "ax.plot(luthi_full_co2_data['years_before_2023'], luthi_full_co2_data['co2_ppmv'], label = 'Luthi 800k Years of co2 Data', color = 'black', alpha = 0.6)\n",
    "ax.set_xlabel('Years Before Present')\n",
    "ax.set_ylabel('c02 PPM')\n",
    "ax.legend()\n",
    "plt.suptitle('IPCC v Luthi 800k Years of co2 Data', weight = 'bold', size = 15)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the trend of atmospheric carbon dioxide levels to include data from the last 20 years, from Mauno Loa, visualises the large jump in atmospheric CO2 in the 21st century. It should be noted that the data from Mauno Loa, located in the Pacific is from a different geographical location than that of the Antartic. This may be exaggerating the jump that is seen in the CO2 levels due to the fact that the measurements are drawn different geographic locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty plot\n",
    "fig, ax = plt.subplots(figsize=(15, 7))\n",
    "\n",
    "# plot the results\n",
    "ax.plot('years_before_2023', 'co2_ppmv', data=fused_data)\n",
    "ax.set_xlabel('Years Before 2023')\n",
    "ax.set_ylabel('CO2 PPM')\n",
    "ax.set_title('800k Years of co2 Data From 2022', weight = 'bold', size = 15)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting the frequency distribution (histogram) of the IPCC carbon dioxide data values it can be see that, in the 800,000 year record, atmospheric levels of co2 over 300 ppm occur infrequently. This suggests the spike in atmospheric carbon dioxide occurring in the last 200 years is an an event that falls outside of the cyclical rise and fall of carbon dioxide during glacial-interglacial periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty plot\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "\n",
    "# plot the results\n",
    "ax.hist(fused_data['co2_ppmv'])\n",
    "ax.set_xlabel('co2_ppmv')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('IPCC Co2 Data Histogram', weight = 'bold', size = 15)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the box plot for the full carbon dioxide dataset it can be seen that carbon dioxide levels above 350 ppmv are outliers and thus are not a normal occurrence. An outlier is described described as an object that deviate significantly from the rest for the objects. This strengthens the hypothesis that the rise in atmospheric CO2 levels in the 21st century is a new phenomenon that is not related to the glacial-interglacial rise and fall of atmospheric carbon dioxide levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(y = 'co2_ppmv', data = full_co2_data, color = 'green').set_title('IPCC 800k Years of CO2 Boxplot', weight = 'bold', size = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monthly CO2 levels since 1979 are available from from https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_mm_gl.txt (Accessed 23 Dec. 2023). Since 1979 there is a clear upward trend CO@ levels. However, while the overall levels are trending upwards the amount of CO2 in the atmosphere appears to fluctuate up and down over time. This indicates that there is a seasonality to the amount of Co2 present in the atmosphere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty plot\n",
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "\n",
    "# plot the results\n",
    "ax.plot(monthly_co2_data['average'])\n",
    "ax.set_xlabel('Year/Month')\n",
    "ax.set_ylabel('CO2 PPM')\n",
    "ax.set_title('Monthly CO2 Trends Since 1979', weight = 'bold', size = 15)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The seasonal variation i n the signal can be understood by de-trending it.\n",
    "\n",
    "The plot below demonstrates the original signal with the trend line overlaid. Beneath that the deconstructed signal is plotted on a subplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fft import fft, rfft\n",
    "from scipy.fft import fftfreq, rfftfreq\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unneeded coluns from the dataset.\n",
    "monthly_co2_data.drop(['year', 'month'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposition = seasonal_decompose(monthly_co2_data['average'])\n",
    "trend = decomposition.trend\n",
    "seasonal = decomposition.seasonal\n",
    "residual = decomposition.resid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on code found at https://ataspinar.com/2020/12/22/time-series-forecasting-with-stochastic-signal-analysis-techniques/ Accessed 28 Dec. 2023\n",
    "\n",
    "# plot size and title\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "# plot the visualisation boxplot\n",
    "plt.subplot(2, 1, 1)\n",
    "sns.lineplot(data = monthly_co2_data['average']).set_title('Original Signal & Trend')\n",
    "sns.lineplot(trend)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "sns.lineplot(seasonal).set_title('De-trended Signal')\n",
    "\n",
    "\n",
    "plt.suptitle('Monthly CO2 Variation Since 1979', fontweight =\"bold\", fontsize=18)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once decomposed the signal can be plotted in the frequency domain. Viewing the signal in this way allows shows how much if the signal lies within each given frequency band. The is achieved by transforming the data to the frequency domain using the Fast Fourier Transform (FFT).\n",
    "\n",
    "The FFT transforms the data from the time domain to the frequency domain. FFT is widely used in a number of fields such as engineering, science, music and mathematics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required functions\n",
    "from scipy.signal import savgol_filter\n",
    "from siml.detect_peaks import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To plot the signal in the frequency domain the signal is de-trended and transformed using the the FFT functions in Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yvalues = monthly_co2_data['average'].values\n",
    "yvalues_trend = savgol_filter(yvalues,25,1)\n",
    "yvalues_detrended = yvalues - yvalues_trend\n",
    "\n",
    "fft_y_  = np.fft.fft(yvalues_detrended)\n",
    "fft_y = np.abs(fft_y_[:len(fft_y_)//2])\n",
    "indices_peaks = detect_peaks(fft_y, mph=25)\n",
    " \n",
    "fft_x_ = np.fft.fftfreq(len(yvalues_detrended))\n",
    "fft_x = fft_x_[:len(fft_x_)//2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The signal is plotted in the frequency domain. \n",
    "\n",
    "The plot shows spikes in signal amplitude at f = 0.08, f = 0.17 and f = o.25\n",
    "\n",
    "$\\implies 1 \\div 0.08 \\approx 12.5$  months\n",
    "\n",
    "$\\implies 1 \\div 0.17 \\approx 5.88$ months\n",
    "\n",
    "$\\implies 1 \\div 0.25 = 4$ months\n",
    "\n",
    "All of the above indicates that there is a seasonal occurrence that happens yearly, every six months and every quarter. This can be explained by the 12 month gaps between the respective highs and lows of summer winter high, the six month gap between the winter high and summer low and the quarterly changes between each of the four seasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty plot  \n",
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "\n",
    "# plot the results\n",
    "ax.plot(fft_x, fft_y)\n",
    "ax.scatter(fft_x[indices_peaks], fft_y[indices_peaks], color='red',marker='D')\n",
    "ax.set_title('Frequency Spectrum of Monthly CO2 Emissions', fontsize=15, weight = 'bold')\n",
    "ax.set_ylabel('Amplitude', fontsize=14)\n",
    "ax.set_xlabel('Frequency [1/month]', fontsize=14)\n",
    " \n",
    " # annotate the peaks\n",
    "for idx in indices_peaks:\n",
    "    x,y = fft_x[idx], fft_y[idx]\n",
    "    text = \"  f = {:.2f}\".format(x,y)\n",
    "    ax.annotate(text, (x,y))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature <a id=\"temperature\"></a>\n",
    "\n",
    "Firstly, the data on which the temperature anomaly was manually calculated for (see [here](#jouzel-2007-temperature-data)) is plotted against the NOAA temperature data . The data that has a manually calculated temperature anomaly is very close to the data sourced from the NOAA, suggesting that the transformation done on that data is close to accurate.\n",
    "\n",
    "Once again the two datasets appear \"out of phase with one another\". This effect, explained above, results from the disparities between the AICC2023 and EDC3 chronologies used to date the samples. The two chronologies are in agreement about the rising and falling CO2 levels but disgree on the age of the samples on the dataset.\n",
    "\n",
    "As the full CO2 data set uses the AICC2023 chronology future analysis on ice core temperature data, in this notebook, will use this chronology so that there is a consistency in comparison of the two variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty plot\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "\n",
    "# plot the results\n",
    "ax.plot(jouzel_temp['aicc2012_years_before_2023'], jouzel_temp['anomaly'], label = 'EPICA Dome C ice core AICC2023 Chronology')\n",
    "ax.plot(noaa_temp['years_before_2023'], noaa_temp['delta_t_c'], label = 'EPICA Dome C ice core EDC3 Chronology', color = 'black', alpha = 0.6)\n",
    "ax.set_xlabel('Years Before 2023')\n",
    "ax.set_ylabel('Temperature Degrees Celsius')\n",
    "ax.legend()\n",
    "plt.suptitle('AICC2023 Chronology vs EDC3 Chronology - 800k Years of Temperature Anomaly', weight = 'bold', size = 15)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparative purposes Jouzel's temperature data (AICC2012 chronology) and the temperature data sourced from [https://www.temperaturerecord.org/#sources](https://www.temperaturerecord.org/#sources) are plotted on the same axis. The data from https://www.temperaturerecord.org/#sources is a global temperature record as opposed to one from a specific location in the case of Jouzel's antartic data.\n",
    "\n",
    "The first observation from the plots of the data is that the data from https://www.temperaturerecord.org/#sources has been scaled. As [outlined here](#further-temperature-data) this data has been scaled to a four degree range. The unscaled EPICA data has large swings in the in the interglacial periods which visually translates as very dramatic when compared to the global temperature anomaly from the scaled dataset.\n",
    "\n",
    "The second notable feature on this plot is that trend line of the fluctuating temperature anomaly for both datasets closely matches each other. That is to say the both datasets are in agreement about the rising and falling temperature anomaly over time.\n",
    "\n",
    "As with the plots of carbon dioxide levels over time, the glacial-interglacial periods are occurring approximately every 100,000 years as seen by the cyclical rise and fall of the temperature anomaly over approximately 100,000 year cycles.\n",
    "\n",
    "The plots indicates that the earth was hotter just over 100,000 years ago than it is now. This suggests that the current period of global warming is not unprecedented. The plot also indicates that until recently the earth was cooling as part of the glacial-interglacial cycle. That trend has been reversed for some reason and the earth has started to heat outside of what would be expected during this cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty plot\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "\n",
    "# plot the results\n",
    "ax.plot(jouzel_temp['aicc2012_years_before_2023'], jouzel_temp['anomaly'], label = 'EPICA Dome C ice core AICC2023 Chronology')\n",
    "ax.plot(full_temp_data['years_before_2023'], full_temp_data['temp_anomaly'], label =\n",
    "        'Composite of Ocean margin sediment cores, lake and ice cores on land and sea surface temperature records.', \n",
    "        color ='black' , alpha = 0.6)\n",
    "ax.set_xlabel('Years Before 2023')\n",
    "ax.set_ylabel('Temperature Degrees Celsius')\n",
    "ax.legend()\n",
    "plt.suptitle('800k Years of Temperature Anomaly', weight = 'bold', size = 15)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot size\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.subplot(1, 1, 1)\n",
    "sns.boxplot(data = jouzel_temp, y  = 'anomaly').set_title(\"Jouzel AICC2012 Chronology 800,000 Years of Antarctic Temperature Anomaly\", weight = 'bold', size = 15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_temp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposition = seasonal_decompose(monthly_temp_data['mean'])\n",
    "trend = decomposition.trend\n",
    "seasonal = decomposition.seasonal\n",
    "residual = decomposition.resid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot size and title\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "# plot the visualisation boxplot\n",
    "plt.subplot(2, 1, 1)\n",
    "sns.lineplot(data = monthly_temp_data['mean']).set_title('Original Signal & Trend')\n",
    "sns.lineplot(trend)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "sns.lineplot(seasonal).set_title('De-trended Signal')\n",
    "\n",
    "\n",
    "plt.suptitle('Monthly Temperature Anomaly Variation Since 1880', fontweight =\"bold\", fontsize=18)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required functions\n",
    "from scipy.signal import savgol_filter\n",
    "from siml.detect_peaks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yvalues = monthly_temp_data['mean'].values\n",
    "yvalues_trend = savgol_filter(yvalues,25,1)\n",
    "yvalues_detrended = yvalues - yvalues_trend\n",
    "\n",
    "fft_y_  = np.fft.fft(yvalues_detrended)\n",
    "fft_y = np.abs(fft_y_[:len(fft_y_)//2])\n",
    "indices_peaks = detect_peaks(fft_y, mph=13)\n",
    " \n",
    "fft_x_ = np.fft.fftfreq(len(yvalues_detrended))\n",
    "fft_x = fft_x_[:len(fft_x_)//2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty plot  \n",
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "\n",
    "# plot the results\n",
    "ax.plot(fft_x, fft_y)\n",
    "ax.scatter(fft_x[indices_peaks], fft_y[indices_peaks], color='red',marker='D')\n",
    "ax.set_title('Frequency Spectrum of Monthly Temperature Anomaly', fontsize=15, weight = 'bold')\n",
    "ax.set_ylabel('Amplitude', fontsize=14)\n",
    "ax.set_xlabel('Frequency [1/month]', fontsize=14)\n",
    " \n",
    " # annotate the peaks\n",
    "for idx in indices_peaks:\n",
    "    x,y = fft_x[idx], fft_y[idx]\n",
    "    text = \"  f = {:.2f}\".format(x,y)\n",
    "    ax.annotate(text, (x,y))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methane <a id=\"methane\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the methane trend for the last 800K years demonstates:\n",
    "\n",
    "+ that there is a massive spike, in approximately the last 200 -300 years, in the level of atmospheric methane. The large spike in this period begs the question is this spike is real or is it the result of bad quality data or some other underlying cause. To answer this question - *\"Over the last two centuries, methane concentrations in the atmosphere have more than doubled, largely due to human-related activities.\"* (US EPA, 2022).\n",
    "\n",
    "+ excluding approximately the last 500 years there is a cyclical rise and fall in methane levels that corresponds with glacial - interglacial periods in earths recent history. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty plot\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "\n",
    "# plot the results\n",
    "ax.plot(full_methane_data['years_before_2023'], full_methane_data['ch4_ppb'])\n",
    "\n",
    "ax.set_xlabel('Years Before 2023')\n",
    "ax.set_ylabel('ch4_ppb')\n",
    "ax.legend()\n",
    "plt.suptitle('800k Years of Methane Trend', weight = 'bold', size = 15)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(full_methane_data['ch4_ppb'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation <a id=\"correlation\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Irish Context <a id=\"irish-context\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Irish Context - Temperature <a id=\"irish-context---temperature\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A time series plot of the Irish temperature data is plotted. The trend line displays the annual variation in mean temperature year on year. Because of the annual variations in this variable the signal can said to be noisy. Plotting the median annual temperature visualises the years in which fell above or below this value. Of note since 2000 there has been only one year that has had an annual median temperature below the median value suggesting that the years in this period have been warmer than the years to this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty plot\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "\n",
    "# plot the results\n",
    "ax.plot(irish_temp_data['annual_mean'])\n",
    "ax.plot(irish_temp_data['median'], label = 'median')\n",
    "ax.set_ylabel('Degrees Celsius')\n",
    "plt.suptitle('Irish Annual Mean Temperature', weight = 'bold', size = 15)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of the mean annual temperature for the last 122 years is plotted. The distribution of data is close to normal. There is a spike in the frequency of datapoints around ten degrees celsius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax =plt.subplots()\n",
    "\n",
    "ax.hist(irish_temp_data['annual_mean'])\n",
    "ax.set_xlabel('Degrees Celsius')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Irish Annual Mean Temperature Distribution 1900 - 2023', weight = 'bold', size = 15)\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a time stepped linear regression it is possible to plot the relationship between time and the average annual mean temperature. Plotting the regression line smooths the variation in annual mean temperature. The line of regression indicates that over the 120 year period since 1900 there has been an increase in the annual mean temperature of approximately 0.8 of a degree celsius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irish_temp_data['time'] =  np.arange(len(irish_temp_data.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "\n",
    "ax.plot('time', 'annual_mean', data=irish_temp_data, color='0.75')\n",
    "ax = sns.regplot(x='time', y='annual_mean', data=irish_temp_data, ci=None, scatter_kws=dict(color='0.25'))\n",
    "ax.set_title('Time Plot of Irish Annual Mean Temperature 1900- 2022', weight = 'bold', size = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Murphy et al. (2023) found that annual mean temperature with warming for the island of Ireland was estimated at 0.88 °C per degree increase in global mean surface temperature. These authors argued that the change in temperature in Ireland has been relatively small and therefore hard to perceive. The increase is more obvious during summer months.\n",
    "\n",
    "Plotting global temperature anomaly against the Irish annual mean temperature from 1900 to 2022 confirms that both variables are trending in the same direction and that Ireland is getting warmer as the globe temperature increases.\n",
    "\n",
    "To plot this data the relevant global data is assigned to a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gta = full_temp_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relevant time period is located within the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gta = gta.iloc[0:122]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is sortd by ascending year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gta = gta.sort_values('year', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A time series index is added to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html [Accessed 21 Dec. 2023]\n",
    "gta['time_series'] = pd.to_datetime(gta['year'], format='%Y')\n",
    "\n",
    "# set time_series column as index\n",
    "# https://stackoverflow.com/questions/27032052/how-do-i-properly-set-the-datetimeindex-for-a-pandas-datetime-object-in-a-datafr [Accessed 21 Dec. 2023].\n",
    "gta = gta.set_index('time_series')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A step is added to the DataFrame to match the Irish Temperature Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gta['time'] =  np.arange(len(gta.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph is plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from code found here - https://stackoverflow.com/questions/5484922/secondary-axis-with-twinx-how-to-add-to-legend Accessed 21 Dec. 2023\n",
    "\n",
    "# create an empty plot\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "\n",
    "g1 = ax.plot('time', 'annual_mean', data = irish_temp_data, color='0.75', label = 'Irish Annual Mean Temperature')\n",
    "ax2 = ax.twinx()\n",
    "g2 = ax2.plot('time', 'temp_anomaly', data = gta, label = 'Global Temperature Anomaly')\n",
    "ax.set_title('Global Temperature Anomaly V Irish Annual Mean Temperature 1900-2022', weight='bold', size=15)\n",
    "\n",
    "# display legends\n",
    "lns = g1+g2\n",
    "labs = [l.get_label() for l in lns]\n",
    "ax.legend(lns, labs, loc=0)\n",
    "\n",
    "# add labels\n",
    "ax.set_xlabel(\"Years From 1900\")\n",
    "ax.set_ylabel('Irish Annual Mean Temperature Degrees Celsius')\n",
    "ax2.set_ylabel(\"Temp Anomaly Degrees Celsius\")\n",
    "\n",
    "#plt.suptitle('Global Temperature Anomaly V Irish Annual Mean Temperature 1900-2022 ', weight='bold', size=15)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two variables can be tested to understand if there is a lag between them. In this case the *y variable*, the mean annual Irish temperature, lags the *x variable* by 0. This indicates that the rise in temperature in Ireland happens at the same time as the rise in the global temperature anomaly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted code from - https://stackoverflow.com/questions/69117617/how-to-find-the-lag-between-two-time-series-using-cross-correlation Accessed 21 Dec. 2023\n",
    "x = gta['temp_anomaly']\n",
    "y = irish_temp_data['annual_mean']\n",
    "correlation = signal.correlate(x-np.mean(x), y - np.mean(y), mode=\"full\")\n",
    "lags = signal.correlation_lags(len(x), len(y), mode=\"full\")\n",
    "lag = lags[np.argmax(abs(correlation))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data analysed above is annual data. Weather variables are subject to seasonal variation. For example, Harmel et al. (2002) and Ruff and Neelin (2012) provide evidence that the distribution of daily temperature data is skewed and that the skewness depends on the season. Temperature for each of the seasons can be anlaysed over time to test the assumption that temperature increases are hard to perceive and seasonal. The data analysed in this section examines data from the Dublin airport weather station. It is recognised that this weather data is from one location and differs from the all Ireland data used by Murphy et al (2023). However, this data can act as a a proxy for national data.\n",
    "\n",
    "As per Wikipedia (Wikipedia Contributors, 2023), Ireland experiences 4 seasons:\n",
    "\n",
    "- Winter = November, December & January\n",
    "- Spring = February, March & April\n",
    "- Summer = May, June & July\n",
    "- Autumn = August, September & October\n",
    "\n",
    "These are the definitions of season that are used in the following section.\n",
    "\n",
    "Plotting boxplots of the Irish monthly temperature in Dublin Airport demonstrates how the median temperature changes month by month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty plot\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "\n",
    "# plot the boxplots\n",
    "sns.boxplot(x='month', y='meant', data =da_monthly_weather_data).set_title('Monthly Mean Temperature Variation Dublin Airport 1941-2023', weight='bold', size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Season specific DataFrames of monthly weather data from Dublin airport are assigned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter DateFrame by seasons - https://kanoki.org/2022/07/16/pandas-filter-dates-by-month-hour-day-or-last-n-days-weeks/ [Accessed 8 Nov. 2023]. \n",
    "winter = da_monthly_weather_data[da_monthly_weather_data.index.month_name().isin(['November', 'December', 'January'])].sort_index(ascending=True)\n",
    "spring = da_monthly_weather_data[da_monthly_weather_data.index.month_name().isin(['February', 'March', 'April'])].sort_index(ascending=True)\n",
    "summer = da_monthly_weather_data[da_monthly_weather_data.index.month_name().isin(['May', 'June', 'July'])].sort_index(ascending=True)\n",
    "autumn = da_monthly_weather_data[da_monthly_weather_data.index.month_name().isin(['August', 'September', 'October'])].sort_index(ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the data points without smoothing will result in a plot that is difficult to interpret due to the monthly variation in mean temperature values. Thge type of smoothin applied is moving average smoothing. This type of smoothing is a common type of smoothing used in time series analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code adapted from https://medium.com/@srv96/smoothing-techniques-for-time-series-data-91cccfd008a2 Accessed 21 Dec. 2023\n",
    "def moving_avarage_smoothing(X,k):\n",
    "\tS = np.zeros(X.shape[0])\n",
    "\tfor t in range(X.shape[0]):\n",
    "\t\tif t < k:\n",
    "\t\t\tS[t] = np.mean(X[:t+1])\n",
    "\t\telse:\n",
    "\t\t\tS[t] = np.sum(X[t-k:t])/k\n",
    "\treturn S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot demonstrates that in spring in winter the mean monthly temperatures have been consistent since 1942 without any obvious dramatic upward trend. Summer and Autumn have been gradually getting warmer. Taking this into account it is consistent with Murphy et al. (2023) in so far as the gradual increase in temperature is relatively small and confined to summer and autumn months. There could be a perception that winter feels colder however the data suggests that the temperature that over the last 80 years there is little variation in the mean monthly temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "\n",
    "ax.plot(moving_avarage_smoothing(winter['meant'], 250), label = 'Winter Mean Temperature', color = 'blue')\n",
    "ax.plot(moving_avarage_smoothing(spring['meant'], 250), label = 'Spring Mean Temperature', color = 'black')\n",
    "ax.plot(moving_avarage_smoothing(summer['meant'], 250), label = 'Summer Mean Temperature', color = 'red')\n",
    "ax.plot(moving_avarage_smoothing(autumn['meant'], 250), label = 'Autumn Mean Temperature', color = 'grey')\n",
    "ax.set_xlabel(\"No of Months\")\n",
    "ax.set_ylabel('Degrees Celsius')\n",
    "ax.legend()\n",
    "plt.suptitle('Season Months Mean Temperature 1942 to 2023 - Dublin Airport', weight='bold', size=15)\n",
    "plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_monthly_weather_data_1980 = da_monthly_weather_data['1980':]['meant']\n",
    "da_monthly_weather_data_1941 = da_monthly_weather_data['1941':'1980']['meant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_monthly_weather_data_1941"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposition = seasonal_decompose(da_monthly_weather_data_1980)\n",
    "trend = decomposition.trend\n",
    "seasonal = decomposition.seasonal\n",
    "residual = decomposition.resid\n",
    "\n",
    "decomposition_1941 = seasonal_decompose(da_monthly_weather_data_1941)\n",
    "trend_1941 = decomposition_1941.trend\n",
    "seasonal_1941 = decomposition_1941.seasonal\n",
    "residual_1941 = decomposition_1941.resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot size and title\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "# plot the visualisation boxplot\n",
    "plt.subplot(2, 1, 1)\n",
    "sns.lineplot(data = da_monthly_weather_data_1980).set_title('Original Signal & Trend')\n",
    "sns.lineplot(trend)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "sns.lineplot(data = da_monthly_weather_data_1941).set_title('Original Signal & Trend')\n",
    "sns.lineplot(trend_1941)\n",
    "\n",
    "plt.suptitle('Irish Mean Monthly Temperature Variation Since 1980', fontweight =\"bold\", fontsize=18)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot size and title\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "sns.lineplot(seasonal).set_title('De-trended Signal')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "sns.lineplot(seasonal_1941).set_title('De-trended Signal')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yvalues = da_monthly_weather_data_1980.values\n",
    "yvalues_trend = savgol_filter(yvalues,25,1)\n",
    "yvalues_detrended = yvalues - yvalues_trend\n",
    "\n",
    "fft_y_  = np.fft.fft(yvalues_detrended)\n",
    "fft_y = np.abs(fft_y_[:len(fft_y_)//2])\n",
    "indices_peaks = detect_peaks(fft_y, mph=50)\n",
    " \n",
    "fft_x_ = np.fft.fftfreq(len(yvalues_detrended))\n",
    "fft_x = fft_x_[:len(fft_x_)//2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yvalues_1941 = da_monthly_weather_data_1941.values\n",
    "yvalues_trend_1941 = savgol_filter(yvalues_1941,25,1)\n",
    "yvalues_detrended_1941 = yvalues_1941 - yvalues_trend_1941\n",
    "\n",
    "fft_y_1941  = np.fft.fft(yvalues_detrended_1941)\n",
    "fft_y1941 = np.abs(fft_y_[:len(fft_y_1941)//2])\n",
    "indices_peaks_1941 = detect_peaks(fft_y1941, mph=50)\n",
    " \n",
    "fft_x_1941 = np.fft.fftfreq(len(yvalues_detrended_1941))\n",
    "fft_x1941 = fft_x_1941[:len(fft_x_1941)//2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty plot  \n",
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "\n",
    "# plot the results\n",
    "ax.plot(fft_x, fft_y)\n",
    "ax.scatter(fft_x[indices_peaks], fft_y[indices_peaks], color='red',marker='D')\n",
    "ax.set_title('Frequency Spectrum of Irish Monthly Mean Temperature', fontsize=15, weight = 'bold')\n",
    "ax.set_ylabel('Amplitude', fontsize=14)\n",
    "ax.set_xlabel('Frequency [1/month]', fontsize=14)\n",
    " \n",
    " # annotate the peaks\n",
    "for idx in indices_peaks:\n",
    "    x,y = fft_x[idx], fft_y[idx]\n",
    "    text = \"  f = {:.2f}\".format(x,y)\n",
    "    ax.annotate(text, (x,y))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty plot  \n",
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "\n",
    "# plot the results\n",
    "ax.plot(fft_x1941, fft_y1941)\n",
    "ax.scatter(fft_x1941[indices_peaks], fft_y1941[indices_peaks], color='red',marker='D')\n",
    "ax.set_title('Frequency Spectrum of Irish Monthly Mean Temperature', fontsize=15, weight = 'bold')\n",
    "ax.set_ylabel('Amplitude', fontsize=14)\n",
    "ax.set_xlabel('Frequency [1/month]', fontsize=14)\n",
    " \n",
    " # annotate the peaks\n",
    "for idx in indices_peaks:\n",
    "    x,y = fft_x1941[idx], fft_y1941[idx]\n",
    "    text = \"  f = {:.2f}\".format(x,y)\n",
    "    ax.annotate(text, (x,y))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Irish Context - Precipitation <a id=\"irish-context---precipitation\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irish_precip_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A column is added to calculate the median value of the annual mean precipitation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irish_precip_data['median'] = irish_precip_data['annual_mean'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annual mean precipitation time series data is plotted. The normal annual variation in precipitation is visualised. It is difficult to discern any trend or pattern in this plot as the signal varies year on year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty plot\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "\n",
    "# plot the results\n",
    "ax.plot(irish_precip_data['annual_mean'])\n",
    "ax.plot(irish_precip_data['median'], label = 'Median of the Mean Values')\n",
    "ax.set_ylabel('Precipitation mm')\n",
    "plt.suptitle('Irish Annual Mean Precipitation 1901 - 2022', weight = 'bold', size = 15)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the linear regression line allows resolution of the trend in annual mean precipitation.\n",
    "\n",
    "A time step is added to the dataset to visualise the linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irish_precip_data['time'] =  np.arange(len(irish_precip_data.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the regression plot, the line of regression indicates that since 1900 the annual mean precipitation is increasing by aprroximately 0.8mm per year. This is a small amount but translates to a 100mm difference over the 123 year period. The gradual increase is so small it is imperceptible, however it is clear that the Irish climate has become wetter over the last 123 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "\n",
    "ax.plot('time', 'annual_mean', data=irish_precip_data, color='0.75')\n",
    "ax = sns.regplot(x='time', y='annual_mean', data=irish_precip_data, ci=None, scatter_kws=dict(color='0.25'))\n",
    "ax.set_title('Time Plot of Irish Annual Mean Precipitation 1900 - 2022', weight = 'bold', size = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An insight into the monthly variation on precipitation is gained by plotting boxplots of historical monthly data. The boxplots demonstrate that winter and autumn tend to be wetter than spring and summer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty plot\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "\n",
    "# plot the boxplots\n",
    "sns.boxplot(x='month', y='median_monthly_precip_mm', \n",
    "            data =irish_monthly_precip_data).set_title('Monthly Mean Precipitation 1711-2016', weight='bold', size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trend in seasonal precipitation gives an indication if changes are more pronounced in one season over another or if the change is spread evenly across all seasons.\n",
    "\n",
    "To plot seasonal trend subsets of seasonal precipitation data are assigned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winter = irish_monthly_precip_data[irish_monthly_precip_data.index.month_name().isin(['November', 'December', 'January'])].sort_index(ascending=True)\n",
    "spring = irish_monthly_precip_data[irish_monthly_precip_data.index.month_name().isin(['February', 'March', 'April'])].sort_index(ascending=True)\n",
    "summer = irish_monthly_precip_data[irish_monthly_precip_data.index.month_name().isin(['May', 'June', 'July'])].sort_index(ascending=True)\n",
    "autumn = irish_monthly_precip_data[irish_monthly_precip_data.index.month_name().isin(['August', 'September', 'October'])].sort_index(ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The seasonal trends are plotted with smoothing applied to the seasonal series to make the signal more readable. The trend clearly demonstrates from approximately halfway through the time period that is included in the data, winter months have become wetter in Ireland as highlighted by the gradual increase in the slope of the blue line below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "\n",
    "ax.plot(moving_avarage_smoothing(winter['median_monthly_precip_mm'], 250), label = 'Winter Median Precipitation', color = 'blue')\n",
    "ax.plot(moving_avarage_smoothing(spring['median_monthly_precip_mm'], 250), label = 'Spring Median Precipitation', color = 'black')\n",
    "ax.plot(moving_avarage_smoothing(summer['median_monthly_precip_mm'], 250), label = 'Summer Median Precipitation', color = 'red')\n",
    "ax.plot(moving_avarage_smoothing(autumn['median_monthly_precip_mm'], 250), label = 'Autumn Median Precipitation', color = 'grey')\n",
    "ax.set_xlabel(\"No of Months\")\n",
    "ax.set_ylabel('mm')\n",
    "ax.legend()\n",
    "plt.suptitle('Season Months Median Precipitation Ireland 1711 - 2016', weight='bold', size=15)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be compared with local preciptation from Dublin airport, albeit during a more condensed time frame. It is also worth noting that that national data is using the median monthly precipitation value while local data (from Dublin airport) uses the amount of precipitation.\n",
    "\n",
    "A time step is added to the monthly precipitation data from Dublin airport."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_monthly_weather_data['time'] =  np.arange(len(da_monthly_weather_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The monthly trend and regression line are plotted. The regression line demonstrates a very shallow slope that indicates that during the period bertween 1941 and 2023 there has been a very small increase in precipitation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18,7))\n",
    "\n",
    "ax.plot('time', 'rain', data=da_monthly_weather_data, color='0.75')\n",
    "ax = sns.regplot(x='time', y='rain', data=da_monthly_weather_data, ci=None, scatter_kws=dict(color='0.25'))\n",
    "ax.set_title('Dublin Airport Monthly Rainfall Data 1941 - 2023', weight = 'bold', size = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seasonal subsets of Dublin Airport precipitation data are created. This allows a plot of the variation in seasonal months precipitation that can be compared to national seasonal variation in precipitation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winter = da_monthly_weather_data[da_monthly_weather_data.index.month_name().isin(['November', 'December', 'January'])].sort_index(ascending=True)\n",
    "spring = da_monthly_weather_data[da_monthly_weather_data.index.month_name().isin(['February', 'March', 'April'])].sort_index(ascending=True)\n",
    "summer = da_monthly_weather_data[da_monthly_weather_data.index.month_name().isin(['May', 'June', 'July'])].sort_index(ascending=True)\n",
    "autumn = da_monthly_weather_data[da_monthly_weather_data.index.month_name().isin(['August', 'September', 'October'])].sort_index(ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No discernible trend is obvious in seasonal variation from Dublin Airport which supports the hypothesis that in ths location there has been little to no increase annual precipitation since 1941, in this location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "\n",
    "ax.plot(moving_avarage_smoothing(winter['rain'], 250), label = 'Dublin Airport Winter Precipitation', color = 'blue')\n",
    "ax.plot(moving_avarage_smoothing(spring['rain'], 250), label = 'Dublin Airport Spring Precipitation', color = 'black')\n",
    "ax.plot(moving_avarage_smoothing(summer['rain'], 250), label = 'Dublin Airport Summer Precipitation', color = 'red')\n",
    "ax.plot(moving_avarage_smoothing(autumn['rain'], 250), label = 'Dublin Airport Autumn Precipitation', color = 'grey')\n",
    "ax.set_xlabel(\"No of Months\")\n",
    "ax.set_ylabel('mm of precipitation')\n",
    "ax.legend()\n",
    "plt.suptitle('Dublin Airport Season Months Median Precipitation Ireland 1941 - 2023', weight='bold', size=15)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive Model <a id=\"predictive-model\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wang et al. (2023) forecasted temperature anomaly outcomes for 2050 using AutoRegressive Integrated Moving Average (ARIMA 1, 1, 3) models, based on four different time periods and observations. The longest period studied was from 1850 to 2021. Based on this data a global temperature anomaly of 0.92 was forecast in 2050.\n",
    "\n",
    "Using global temperature anomaly data for the same period a linear regression model can be created and used to predict the temperature in 2050."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy of the full global temperature dataset\n",
    "full_temp_data_training = full_temp_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using iloc the period from 1850 to 2021 is identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_temp_data_training = full_temp_data_training.iloc[1:173]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_temp_data_training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is sorted in ascending order based on the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_temp_data_training = full_temp_data_training.sort_values('year', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A time series is created using the *year* variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html [Accessed 21 Dec. 2023]\n",
    "full_temp_data_training['time_series'] = pd.to_datetime(full_temp_data_training['year'], format='%Y')\n",
    "\n",
    "# set time_series column as index\n",
    "# https://stackoverflow.com/questions/27032052/how-do-i-properly-set-the-datetimeindex-for-a-pandas-datetime-object-in-a-datafr [Accessed 21 Dec. 2023].\n",
    "full_temp_data_training = full_temp_data_training.set_index('time_series')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A time dummy, which counts off time steps in the series from beginning to end, is added to the data frame. This is used to plot the linear regression line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_temp_data_training['time'] =  np.arange(len(full_temp_data_training.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Seaborn's *regplot* the linear regression line is plotted over the actual datapoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an empty plot is created\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "\n",
    "# the linear regression line is plotted over the actual datapoints\n",
    "ax.plot('time', 'temp_anomaly', data=full_temp_data_training, color='0.75')\n",
    "ax = sns.regplot(x='time', y='temp_anomaly', data=full_temp_data_training, ci=None, scatter_kws=dict(color='0.25'))\n",
    "ax.set_title('Time Plot of Global Temperature Anomaly 1850 - 2021', weight = 'bold', size = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A date range time series is created for a synthesised dataset that covers the period from 1850 to 2050. This will be fed into the linear regression model to predict the temperature anomaly in 2050."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from - https://pandas.pydata.org/docs/reference/api/pandas.date_range.html [Accessed 21 Dec. 2023].\n",
    "dti = pd.date_range(start=\"1850\", end='2050', freq = 'Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time series is assigned an the index in a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code adapted from - https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html [Accessed 13 Nov. 2023].\n",
    "synthesised_dataset = pd.DataFrame(index=dti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthesised_dataset['time'] =  np.arange(len(synthesised_dataset.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code adapted from - https://www.kaggle.com/code/ryanholbrook/linear-regression-with-time-series [Accessed 21 Dec. 2023].\n",
    "\n",
    "# Training data\n",
    "X = full_temp_data_training.loc[:, ['time']]  # features\n",
    "y = full_temp_data_training.loc[:, 'temp_anomaly']  # target\n",
    "\n",
    "# Train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = synthesised_dataset.loc[:, ['time']]  # features\n",
    "\n",
    "# Store the fitted values as a time series with the same time index as the synthesised data\n",
    "y_pred = pd.Series(model.predict(X), index=X.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the resultant series indicates that the global temperature anomaly goes from -0.526775 in 1850 to 0.687790 on the 31st of December 2049. Assuming that other variables (CO2 concentrations, methane concentrations, etc.) that are causing the temperature anomaly to change remain as they are now, this equates to $\\approx$ 1.2 degrees celsius increase, from 1850, in the global temperature anomaly by 2050.\n",
    "\n",
    "A predicted global temperature anomaly of 0.68 degrees celsius in 2050 is consistent the the prediction (0.92 degrees celsius) of Wang et al. (2023)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(y_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References <a id=\"references\"></a>\n",
    "\n",
    "admin (2020). Time-Series forecasting with Stochastic Signal Analysis techniques. [online] ML Fundamentals. Available at: https://ataspinar.com/2020/12/22/time-series-forecasting-with-stochastic-signal-analysis-techniques/ [Accessed 28 Dec. 2023].\n",
    "\n",
    "Annan, J.D. and Hargreaves, J.C. (2013). A new global reconstruction of temperature changes at the Last Glacial Maximum. Climate of the Past, 9(1), pp.367–376. doi:https://doi.org/10.5194/cp-9-367-2013.\n",
    "\n",
    "Bazin, L., Amaëlle Landais, Bénédicte Lemieux‐Dudon, Toye, H., Veres, D., Frédéric Parrenin, Martinerie, P., Ritz, C., Capron, É., Vladimir Ya. Lipenkov, Marie-France Loutre, Raynaud, D., Vinther, B.M., Svensson, A., Sune Olander Rasmussen, Severi, M., Blunier, T., Leuenberger, M., Fischer, H. and Valérie Masson‐Delmotte (2013). The Antarctic ice core chronology (AICC2012). doi:https://doi.org/10.1594/pangaea.824894.\n",
    "\n",
    "Bereiter et al. (2014), Revision of the EPICA Dome C CO2 record from 800 to 600 kyr before present, Geophysical Research Letters, doi: 10.1002/2014GL061957.\n",
    "\n",
    "Bintanja, R., van de Wal, R.S.W. and Oerlemans, J. (2005). Modelled atmospheric temperatures and global sea levels over the past million years. Nature, 437(7055), pp.125–128. doi:https://doi.org/10.1038/nature03975.\n",
    "\n",
    "climateknowledgeportal.worldbank.org. (n.d.). World Bank Climate Change Knowledge Portal. [online] Available at: https://climateknowledgeportal.worldbank.org/country/ireland/climate-data-historical. [Accessed 20 Dec. 2023].\n",
    "\n",
    "Dash, S. (2020). Smoothing Techniques for time series data. [online] Medium. Available at: https://medium.com/@srv96/smoothing-techniques-for-time-series-data-91cccfd008a2.[Accessed 21 Dec. 2023].\n",
    "\n",
    "Datopian (n.d.). Global Temperature Time Series. [online] DataHub. Available at: https://datahub.io/core/global-temp#readme. [Accessed 28 Dec. 2023].\n",
    "\n",
    "Etheridge, D. M., Steele, L. P., Francey, R. J., and Langenfelds, R. L., 1998, Atmospheric methane between 1000 A.D. and present: Evidence of anthropogenic emissions and climatic variability J. Geophys. Res. Vol. 103, No. D13, p. 15,979 (98JD00923)\n",
    "\n",
    "cs95 (2018). Pandas Merging 101. [online] Stack Overflow. Available at: https://stackoverflow.com/questions/53645882/pandas-merging-101. [Accessed 18 Dec. 2023].\n",
    "\n",
    "GeeksforGeeks. (2018). Python | Pandas DataFrame.astype(). [online] Available at: https://www.geeksforgeeks.org/python-pandas-dataframe-astype/. [Accessed 15 Dec. 2023].\n",
    "\n",
    "GeeksforGeeks. (2020). Change the line opacity in Matplotlib. [online] Available at: https://www.geeksforgeeks.org/change-the-line-opacity-in-matplotlib/. [Accessed 19 Dec. 2023]\n",
    "\n",
    "Harmel RD, Richardson CW, Hanson CL, Johnson GL (2002) Evaluating the adequacy of simulating maximum and minimum daily air temperature with the normal distribution. J Appl Meteorol 41(7):744–753. https://doi.org/10.1175/1520-0450(2002)041%3c0744:ETAOSM%3e2.0.CO;2\n",
    "\n",
    "Jouzel, Jean; Masson-Delmotte, Valerie (2007): EPICA Dome C Ice Core 800KYr deuterium data and temperature estimates. PANGAEA, https://doi.org/10.1594/PANGAEA.683655\n",
    "\n",
    "kaggle.com. (n.d.). Linear Regression With Time Series. [online] Available at: https://www.kaggle.com/code/ryanholbrook/linear-regression-with-time-series. [Accessed 21 Dec. 2023].\n",
    "\n",
    "Lemieux-Dudon, B., Blayo, E., Petit, J.-R., Waelbroeck, C., Svensson, A., Ritz, C., Barnola, J.-M., Narcisi, B.M. and Parrenin, F. (2010). Consistent dating for Antarctic and Greenland ice cores. Quaternary Science Reviews, 29(1-2), pp.8–20. doi:https://doi.org/10.1016/j.quascirev.2009.11.010.\n",
    "\n",
    "Lisiecki, L.E. and Raymo, M.E. (2005). A Pliocene-Pleistocene stack of 57 globally distributed benthic δ18O records. Paleoceanography, 20(1), p.n/a-n/a. doi:https://doi.org/10.1029/2004pa001071.\n",
    "\n",
    "Loulergue, L., Schilt, A., Spahni, R., Masson-Delmotte, V., Blunier, T., Lemieux, B., Barnola, J.-M., Raynaud, D., Stocker, T.F. and Chappellaz, J. (2008). Orbital and millennial-scale features of atmospheric CH4 over the past 800,000 years. Nature, [online] 453(7193), pp.383–386. doi:https://doi.org/10.1038/nature06950.\n",
    "\n",
    "Lüthi, D., Le Floch, M., Bereiter, B., Blunier, T., Barnola, J.-M., Siegenthaler, U., Raynaud, D., Jouzel, J., Fischer, H., Kawamura, K. and Stocker, T.F. (2008). High-resolution carbon dioxide concentration record 650,000–800,000 years before present. Nature, 453(7193), pp.379–382. doi:https://doi.org/10.1038/nature06949.\n",
    "\n",
    "Marcott, S.A., Shakun, J.D., Clark, P.U. and Mix, A.C. (2013). A Reconstruction of Regional and Global Temperature for the Past 11,300 Years. Science, 339(6124), pp.1198–1201. doi:https://doi.org/10.1126/science.1228026.\n",
    "\n",
    "Name, Y. (2022). Pandas filter dates by month, hour, day and last N days & weeks. [online] kanoki. Available at: https://kanoki.org/2022/07/16/pandas-filter-dates-by-month-hour-day-or-last-n-days-weeks/ [Accessed 9 Nov. 2023].\n",
    "\n",
    "Naveen (2022). How to Rename Columns With List in Pandas. [online] Spark By {Examples}. Available at: https://sparkbyexamples.com/pandas/rename-columns-with-list-in-pandas-dataframe/ [Accessed 13 Dec. 2023].\n",
    "\n",
    "note.nkmk.me. (2023). pandas: Interpolate NaN (missing values) with interpolate() | note.nkmk.me. [online] Available at: https://note.nkmk.me/en/python-pandas-interpolate/ [Accessed 23 Dec. 2023].\n",
    "\n",
    "pandas.pydata.org. (2023). pandas.DataFrame — pandas 1.2.4 documentation. [online] Available at: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html. [ Accessed 21 Dec. 2023].\n",
    "\n",
    "pandas.pydata.org. (n.d.). pandas.concat — pandas 1.3.4 documentation. [online] Available at: https://pandas.pydata.org/docs/reference/api/pandas.concat.html. [Accessed 13 Dec. 2023].\n",
    "\n",
    "pandas.pydata.org. (n.d.). pandas.DataFrame.drop — pandas 1.2.4 documentation. [online] Available at: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html. [Accessed 13 Dec. 2023].\n",
    "\n",
    "pandas.pydata.org. (n.d.). pandas.date_range — pandas 2.1.4 documentation. [online] Available at: https://pandas.pydata.org/docs/reference/api/pandas.date_range.html [Accessed 21 Dec. 2023].\n",
    "\n",
    "pandas.pydata.org. (n.d.). pandas.to_datetime — pandas 1.3.4 documentation. [online] Available at: https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html. [Accessed 21 Dec. 2023].\n",
    "\n",
    "Parrenin, F., Barnola, J.-M. ., Beer, J., Blunier, T., Castellano, E., Chappellaz, J., Dreyfus, G., Fischer, H., Fujita, S., Jouzel, J., Kawamura, K., Lemieux-Dudon, B., Loulergue, L., Masson-Delmotte, V., Narcisi, B., Petit, J.-R. ., Raisbeck, G., Raynaud, D., Ruth, U. and Schwander, J. (2007). The EDC3 chronology for the EPICA Dome C ice core. Climate of the Past, 3(3), pp.485–497. doi:https://doi.org/10.5194/cp-3-485-2007.\n",
    "\n",
    "practicaldatascience.co.uk. (2022). How to reorder Pandas dataframe columns. [online] Available at: https://practicaldatascience.co.uk/data-science/how-to-reorder-pandas-dataframe-columns. [Accessed 13 Dec. 2023].\n",
    "\n",
    "saturncloud.io. (2023). How to Sort Pandas DataFrame by One or Multiple Column | Saturn Cloud Blog. [online] Available at: https://saturncloud.io/blog/\n",
    "how-to-sort-pandas-dataframe-from-one-column/ [Accessed 13 Dec. 2023].\n",
    "\n",
    "Shakun, J.D., Clark, P.U., He, F., Marcott, S.A., Mix, A.C., Liu, Z., Otto-Bliesner, B., Schmittner, A. and Bard, E. (2012). Global warming preceded by increasing carbon dioxide concentrations during the last deglaciation. Nature, [online] 484(7392), pp.49–54. doi:https://doi.org/10.1038/nature10915.\n",
    "\n",
    "Snyder, C.W. (2016). Evolution of global temperature over the past two million years. Nature, [online] 538(7624), pp.226–228. doi:https://doi.org/10.1038/nature19798.\n",
    "\n",
    "Stack Overflow. (n.d.). Cleanly combine year and month columns to single date column with pandas. [online] Available at: https://stackoverflow.com/questions/48304927/cleanly-combine-year-and-month-columns-to-single-date-column-with-pandas [Accessed 21 Dec. 2023].\n",
    "\n",
    "Stack Overflow. (n.d.). How do I get a list of all the duplicate items using pandas in python? [online] Available at: https://stackoverflow.com/questions/14657241/how-do-i-get-a-list-of-all-the-duplicate-items-using-pandas-in-python [Accessed 22 Dec. 2023].\n",
    "‌\n",
    "Stack Overflow. (n.d.). How do I properly set the Datetimeindex for a Pandas datetime object in a dataframe? [online] Available at: https://stackoverflow.com/questions/27032052/how-do-i-properly-set-the-datetimeindex-for-a-pandas-datetime-object-in-a-datafr. [Accessed 21 Dec. 2023].\n",
    "\n",
    "Stack Overflow. (n.d.). How to find the lag between two time series using cross-correlation. [online] Available at: https://stackoverflow.com/questions/69117617/how-to-find-the-lag-between-two-time-series-using-cross-correlation [Accessed 21 Dec. 2023].\n",
    "\n",
    "Stack Overflow. (n.d.). Reading tab-delimited file with Pandas - works on Windows, but not on Mac. [online] Available at: https://stackoverflow.com/questions/27896214/reading-tab-delimited-file-with-pandas-works-on-windows-but-not-on-mac [Accessed 15 Dec. 2023].\n",
    "\n",
    "Stack Overflow. (n.d.). Rounding down values in Pandas dataframe column with NaNs. [online] Available at: https://stackoverflow.com/questions/35873927/rounding-down-values-in-pandas-dataframe-column-with-nans [Accessed 23 Dec. 2023].\n",
    "\n",
    "Stack Overflow. (n.d.). Secondary axis with twinx(): how to add to legend. [online] Available at: https://stackoverflow.com/questions/5484922/secondary-axis-with-twinx-how-to-add-to-legend. [Accessed 21 Dec. 2023]\n",
    "\n",
    "US EPA (2022). Importance of Methane. [online] US EPA. Available at: https://www.epa.gov/gmi/importance-methane. [Accessed 18 Dec. 2023]\n",
    "\n",
    "Veres, D., Bazin, L., Landais, A., Toyé Mahamadou Kele, H., Lemieux-Dudon, B., Parrenin, F., Martinerie, P., Blayo, E., Blunier, T., Capron, E., Chappellaz, J., Rasmussen, S.O., Severi, M., Svensson, A., Vinther, B. and Wolff, E.W. (2013). The Antarctic ice core chronology (AICC2012): an optimized multi-parameter and multi-site dating approach for the last 120 thousand years. Climate of the Past, 9(4), pp.1733–1748. doi:https://doi.org/10.5194/cp-9-1733-2013.\n",
    "\n",
    "Wang, L., Wang, L., Li, Y. and Wang, J. (2023). A century-long analysis of global warming and earth temperature using a random walk with drift approach. Decision Analytics Journal, [online] 7, p.100237. doi:https://doi.org/10.1016/j.dajour.2023.100237.\n",
    "\n",
    "Wikipedia Contributors (2023). Irish calendar. [online] Wikipedia. Available at: https://en.wikipedia.org/wiki/Irish_calendar [Accessed 9 Nov. 2023].\n",
    "\n",
    "www.digitalocean.com. (n.d.). Pandas read_excel() - Reading Excel File in Python | DigitalOcean. [online] Available at: https://www.digitalocean.com/community/tutorials/pandas-read_excel-reading-excel-file-in-python. [19 Dec. 2023].\n",
    "\n",
    "www.ncei.noaa.gov. (n.d.). Global Surface Temperature Anomalies | National Centers for Environmental Information (NCEI). [online] Available at: https://www.ncei.noaa.gov/access/monitoring/global-temperature-anomalies/.\n",
    "\n",
    "www.shanelynn.ie. (n.d.). iloc, loc, and ix for data selection in Python Pandas | Shane Lynn. [online] Available at: https://www.shanelynn.ie/pandas-iloc-loc-select-rows-and-columns-dataframe/. [Accessed 19 Dec. 2023]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Associated Reading <a id=\"associated-reading\"></a>\n",
    "\n",
    "Matplotlib (2012). Matplotlib: Python plotting — Matplotlib 3.1.1 documentation. [online] Matplotlib.org. Available at: https://matplotlib.org/. [Accessed 13 Dec. 2023].\n",
    "\n",
    "Pandas (2018). Python Data Analysis Library — pandas: Python Data Analysis Library. [online] Pydata.org. Available at: https://pandas.pydata.org/. [Accessed 13 Dec. 2023]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook Ends"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
